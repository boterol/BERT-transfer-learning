{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Texto con BERT y Hugging Face\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Ohtar10/icesi-nlp/blob/main/Sesion4/1-text-classification-with-hf.ipynb)\n",
    "\n",
    "En este notebook implementaremos un clasificador de noticias en español utilizando transformers pero ya basandonos en un modelo pre-entrenado tipo Bidirectional Encoder Representation from Transformers o BERT por sus siglas y disponible en Hugging Face Hub. El propósito de esta tarea es aprender a utilizar modelos pre-entrenados que por si mismos, sería sumamente costoso entrenar desde cero, tanto por el poder de computo como la disponibilidad de datos de entrenamiento. Entonces gran parte de la labor ya ha sido realizada por nosotros. Nuestra tarea ahora es especializar el modelo en la tarea que tenemos a la mano.\n",
    "\n",
    "En esta ocasión, vamos a apartarnos de Pytorch Lightning y harémos uso extensivo de la herramientas de Hugging Face, las cuales están especialmente desarrolladas para este tipo de tareas, incluyendo la interacción con modelos pre-entrenados.\n",
    "\n",
    "#### Referencias\n",
    "- Dataset: https://huggingface.co/datasets/MarcOrfilaCarreras/spanish-news\n",
    "- [BETO: Spanish BERT](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased)\n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](http://arxiv.org/abs/1810.04805)\n",
    "- [Natural Language Processing with Transformers: Building Language Applications With Hugging Face](https://www.amazon.com/Natural-Language-Processing-Transformers-Applications/dp/1098103246)\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/v4.41.3/en/index)\n",
    "- [Hugging Face Accelerate](https://huggingface.co/docs/accelerate/index)\n",
    "- [Hugging Face Evaluate](https://huggingface.co/docs/evaluate/v0.4.0/en/index)\n",
    "- [Hugging Face Datasets](https://huggingface.co/docs/datasets/v2.19.0/en/index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET wikiANN (es)\n",
    "\n",
    "#### **Columnas principales**\n",
    "\n",
    "* `tokens`: Lista de palabras (ej. `[\"José\", \"Luis\", \"García\"]`).\n",
    "* `ner_tags`: Lista de enteros que representan etiquetas IOB.\n",
    "* `langs`: Idioma por token (aquí siempre `\"es\"`).\n",
    "* `spans`: Entidades completas (ej. `\"PER: José Luis García\"`).\n",
    "\n",
    "#### **Formato de Etiquetas (IOB)**\n",
    "\n",
    "El dataset usa un esquema IOB con 3 tipos de entidades: **Persona (PER)**, **Organización (ORG)** y **Lugar (LOC)**.\n",
    "\n",
    "| ID | Tag   | Significado               |\n",
    "| -- | ----- | ------------------------- |\n",
    "| 0  | O     | Outside (ninguna entidad) |\n",
    "| 1  | B-PER | Beginning of Person       |\n",
    "| 2  | I-PER | Inside Person             |\n",
    "| 3  | B-ORG | Beginning of Organization |\n",
    "| 4  | I-ORG | Inside Organization       |\n",
    "| 5  | B-LOC | Beginning of Location     |\n",
    "| 6  | I-LOC | Inside Location           |\n",
    "\n",
    "**Número de etiquetas (`num_labels`) = 7**\n",
    "\n",
    "#### **Ejemplo de muestra**\n",
    "\n",
    "```python\n",
    "{\n",
    " 'tokens': ['REDIRECCIÓN', 'José', 'Luis', 'García'],\n",
    " 'ner_tags': [0, 1, 2, 2],\n",
    " 'langs': ['es', 'es', 'es', 'es'],\n",
    " 'spans': ['PER: José Luis García']\n",
    "}\n",
    "```\n",
    "\n",
    "Interpretación:\n",
    "\n",
    "```\n",
    "'REDIRECCIÓN' → O\n",
    "'José'        → B-PER\n",
    "'Luis'        → I-PER\n",
    "'García'      → I-PER\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_701308/2396000874.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "installed_packages = [package.key for package in pkg_resources.working_set]\n",
    "IN_COLAB = 'google-colab' in installed_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!test '{IN_COLAB}' = 'True' && wget https://github.com/boterol/BERT-transfer-learning/blob/main/requirements.txt && pip install -r requirements.txt\n",
    "!test '{IN_COLAB}' = 'True' && sudo apt-get update -y\n",
    "!test '{IN_COLAB}' = 'True' && sudo apt-get install python3.10 python3.10-distutils python3.10-lib2to3 -y\n",
    "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.11 2\n",
    "!test '{IN_COLAB}' = 'True' && sudo update-alternatives --install /usr/local/bin/python python /usr/bin/python3.10 1\n",
    "!test '{IN_COLAB}' = 'True' && pip install lightning datasets 'transformers[torch]' sentence-transformers torchinfo evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el dataset\n",
    "Este es un dataset pequeño de frases en idioma español con sus respectivas labels de los tipos de entidades. El dataset está disponible en el HuggingFace Hub y puede ser fácilmente descargado con la librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>langs</th>\n",
       "      <th>spans</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 5, 6, 6, 6]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Algarrobo ( Chile )]</td>\n",
       "      <td>REDIRECCIÓN Algarrobo ( Chile )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 2]</td>\n",
       "      <td>[es, es, es]</td>\n",
       "      <td>[PER: W. G. Sebald]</td>\n",
       "      <td>W. G. Sebald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Tamás Faragó]</td>\n",
       "      <td>' '' Entrenador / a '' Tamás Faragó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 3, 4, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Società Sportiva Virtus Lanciano 1924]</td>\n",
       "      <td>REDIRECCIÓN Società Sportiva Virtus Lanciano 1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[3, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[ORG: Houses of the Holy]</td>\n",
       "      <td>Houses of the Holy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 5, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Luanda]</td>\n",
       "      <td>** Luanda ( Embajada )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0, 1, 2, 2]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[PER: José Luis García]</td>\n",
       "      <td>REDIRECCIÓN José Luis García</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[5, 6, 6, 0]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[LOC: Condado de Duplin]</td>\n",
       "      <td>Condado de Duplin suroeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0, 5, 6, 6, 6]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: São Pedro do Funchal]</td>\n",
       "      <td>REDIRECCIÓN São Pedro do Funchal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0, 0, 5, 0, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: Huelva]</td>\n",
       "      <td>50px '' Huelva '' '146.173 hab .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0, 5, 6, 6]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[LOC: Departamento de Cajamarca]</td>\n",
       "      <td>REDIRECCIÓN Departamento de Cajamarca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 4, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Ejército del Norte]</td>\n",
       "      <td>Posteriormente se incorporó al Ejército del No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0, 3, 4, 4]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[ORG: FC Progresul București]</td>\n",
       "      <td>REDIRECCIÓN FC Progresul București</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5, 6, 0, 5, 0, 5, 6, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: San Francisco, LOC: California, LOC: Est...</td>\n",
       "      <td>San Francisco , California , Estados Unidos .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Pedro de Alcántara Téllez-Girón y Beaufo...</td>\n",
       "      <td>' '' Pedro de Alcántara Téllez-Girón y Beaufor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[0, 3, 4, 0]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[ORG: E.T .]</td>\n",
       "      <td>`` E.T . ''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[0, 0, 1, 2, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Marion Bartoli]</td>\n",
       "      <td>' '' Marion Bartoli '' '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 0, 1, 2]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[PER: Peter McNamara, PER: Paul McNamee]</td>\n",
       "      <td>Peter McNamara - Paul McNamee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 0, 5, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Lombard Street, LOC: Londres]</td>\n",
       "      <td>Anteriormente estaba situada en Lombard Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0, 0, 0, 0, 3, 4, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Toronto FC]</td>\n",
       "      <td>Actualmente juega en el Toronto FC .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[0, 3, 4, 4]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[ORG: Estación de Madrid-Chamartín]</td>\n",
       "      <td>REDIRECCIÓN Estación de Madrid-Chamartín</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[0, 3, 4, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Niños Héroes ( estación )]</td>\n",
       "      <td>REDIRECCIÓN Niños Héroes ( estación )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Museo Nacional de Arqueología , Antropol...</td>\n",
       "      <td>REDIRECCIÓN Museo Nacional de Arqueología , An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[0, 3, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[ORG: Students in Free Enterprise]</td>\n",
       "      <td>REDIRECCIÓN Students in Free Enterprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[0, 1, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Lope Díez de Aux y Armendáriz]</td>\n",
       "      <td>REDIRECCIÓN Lope Díez de Aux y Armendáriz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[0, 0, 5, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Bausen]</td>\n",
       "      <td>' '' Bausen '' '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[3, 4, 4, 0, 5, 6, 0, 5]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Estadio Pedro Marrero, LOC: La Habana, L...</td>\n",
       "      <td>Estadio Pedro Marrero , La Habana , Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[0, 0, 0, 3, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[ORG: CBGB]</td>\n",
       "      <td>el mítico local CBGB .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[0, 1, 2, 2, 2]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[PER: Ángel ( Buffyverso )]</td>\n",
       "      <td>REDIRECCIÓN Ángel ( Buffyverso )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[0, 0, 5, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Cacabelos]</td>\n",
       "      <td>' '' Cacabelos '' '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[0, 3, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[ORG: Revista Colombiana de Estadística]</td>\n",
       "      <td>REDIRECCIÓN Revista Colombiana de Estadística</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[0, 0, 5, 6, 6, 6, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: Nueva Valencia del Rey]</td>\n",
       "      <td>Así surgió Nueva Valencia del Rey .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[0, 0, 5, 0, 5, 0]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: Berlín, LOC: Alemania]</td>\n",
       "      <td>Springer-Verlag , Berlín , Alemania .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[0, 1, 2, 2]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[PER: Gala Éluard Dalí]</td>\n",
       "      <td>REDIRECCIÓN Gala Éluard Dalí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[5, 6, 6, 6, 6]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Avenida Revolución ( Tijuana )]</td>\n",
       "      <td>Avenida Revolución ( Tijuana )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[5, 0, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Paraná]</td>\n",
       "      <td>Paraná ( 247.310 hab .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[0, 1, 2, 2]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[PER: Víctor González Reynoso]</td>\n",
       "      <td>REDIRECCIÓN Víctor González Reynoso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[0, 1, 2, 2, 2, 2]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Federico II Eugenio de Wurtemberg]</td>\n",
       "      <td>REDIRECCIÓN Federico II Eugenio de Wurtemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es, es, es, e...</td>\n",
       "      <td>[LOC: Zaragoza]</td>\n",
       "      <td>Sin embargo , su padre le ordenó ir a Zaragoza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es, es, es, e...</td>\n",
       "      <td>[LOC: Estados UnidosSerie]</td>\n",
       "      <td>Tallahassee]] , Estados UnidosSerie regular $ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 2, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[PER: Luis I de Flandes]</td>\n",
       "      <td>Su hijo fue Luis I de Flandes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[0, 3, 4, 4, 4]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[ORG: Gossip ( banda )]</td>\n",
       "      <td>REDIRECCIÓN Gossip ( banda )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[0, 1, 2, 2]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[PER: Historieta en España]</td>\n",
       "      <td>REDIRECCIÓN Historieta en España</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[1, 2, 0, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[PER: Iván Brzić]</td>\n",
       "      <td>Iván Brzić ( 1-34 )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[0, 0, 3, 4, 4, 4, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Tsubasa : Reservoir Chronicle]</td>\n",
       "      <td>=== En Tsubasa : Reservoir Chronicle '' ===</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[0, 3, 4, 4, 0, 0]</td>\n",
       "      <td>[es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Ratonero de Praga]</td>\n",
       "      <td>'' Ratonero de Praga '' '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[1, 2, 0, 0]</td>\n",
       "      <td>[es, es, es, es]</td>\n",
       "      <td>[PER: John Taylor]</td>\n",
       "      <td>John Taylor - bajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[LOC: Buenos Aires]</td>\n",
       "      <td>Para realizar sus estudios secundarios debió v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[5, 6, 6, 6, 6]</td>\n",
       "      <td>[es, es, es, es, es]</td>\n",
       "      <td>[LOC: Fuente el Saz de Jarama]</td>\n",
       "      <td>Fuente el Saz de Jarama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[3, 4, 4, 4, 4, 4, 4, 0]</td>\n",
       "      <td>[es, es, es, es, es, es, es, es]</td>\n",
       "      <td>[ORG: Batman : The Brave and the Bold]</td>\n",
       "      <td>Batman : The Brave and the Bold ''</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ner_tags  \\\n",
       "0                                 [0, 5, 6, 6, 6]   \n",
       "1                                       [1, 2, 2]   \n",
       "2                        [0, 0, 0, 0, 0, 0, 1, 2]   \n",
       "3                              [0, 3, 4, 4, 4, 4]   \n",
       "4                                    [3, 4, 4, 4]   \n",
       "5                                 [0, 5, 0, 0, 0]   \n",
       "6                                    [0, 1, 2, 2]   \n",
       "7                                    [5, 6, 6, 0]   \n",
       "8                                 [0, 5, 6, 6, 6]   \n",
       "9                           [0, 0, 5, 0, 0, 0, 0]   \n",
       "10                                   [0, 5, 6, 6]   \n",
       "11                       [0, 0, 0, 0, 3, 4, 4, 0]   \n",
       "12                                   [0, 3, 4, 4]   \n",
       "13                       [5, 6, 0, 5, 0, 5, 6, 0]   \n",
       "14              [0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0]   \n",
       "15                                   [0, 3, 4, 0]   \n",
       "16                             [0, 0, 1, 2, 0, 0]   \n",
       "17                                [1, 2, 0, 1, 2]   \n",
       "18                    [0, 0, 0, 0, 3, 4, 0, 5, 0]   \n",
       "19                          [0, 0, 0, 0, 3, 4, 0]   \n",
       "20                                   [0, 3, 4, 4]   \n",
       "21                             [0, 3, 4, 4, 4, 4]   \n",
       "22              [0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4]   \n",
       "23                                [0, 3, 4, 4, 4]   \n",
       "24                          [0, 1, 2, 2, 2, 2, 2]   \n",
       "25                                [0, 0, 5, 0, 0]   \n",
       "26                       [3, 4, 4, 0, 5, 6, 0, 5]   \n",
       "27                                [0, 0, 0, 3, 0]   \n",
       "28                                [0, 1, 2, 2, 2]   \n",
       "29                                [0, 0, 5, 0, 0]   \n",
       "30                                [0, 3, 4, 4, 4]   \n",
       "31                          [0, 0, 5, 6, 6, 6, 0]   \n",
       "32                             [0, 0, 5, 0, 5, 0]   \n",
       "33                                   [0, 1, 2, 2]   \n",
       "34                                [5, 6, 6, 6, 6]   \n",
       "35                                [5, 0, 0, 0, 0]   \n",
       "36                                   [0, 1, 2, 2]   \n",
       "37                             [0, 1, 2, 2, 2, 2]   \n",
       "38        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0]   \n",
       "39  [0, 0, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "40                       [0, 0, 0, 1, 2, 2, 2, 0]   \n",
       "41                                [0, 3, 4, 4, 4]   \n",
       "42                                   [0, 1, 2, 2]   \n",
       "43                                [1, 2, 0, 0, 0]   \n",
       "44                       [0, 0, 3, 4, 4, 4, 0, 0]   \n",
       "45                             [0, 3, 4, 4, 0, 0]   \n",
       "46                                   [1, 2, 0, 0]   \n",
       "47              [0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0]   \n",
       "48                                [5, 6, 6, 6, 6]   \n",
       "49                       [3, 4, 4, 4, 4, 4, 4, 0]   \n",
       "\n",
       "                                                langs  \\\n",
       "0                                [es, es, es, es, es]   \n",
       "1                                        [es, es, es]   \n",
       "2                    [es, es, es, es, es, es, es, es]   \n",
       "3                            [es, es, es, es, es, es]   \n",
       "4                                    [es, es, es, es]   \n",
       "5                                [es, es, es, es, es]   \n",
       "6                                    [es, es, es, es]   \n",
       "7                                    [es, es, es, es]   \n",
       "8                                [es, es, es, es, es]   \n",
       "9                        [es, es, es, es, es, es, es]   \n",
       "10                                   [es, es, es, es]   \n",
       "11                   [es, es, es, es, es, es, es, es]   \n",
       "12                                   [es, es, es, es]   \n",
       "13                   [es, es, es, es, es, es, es, es]   \n",
       "14       [es, es, es, es, es, es, es, es, es, es, es]   \n",
       "15                                   [es, es, es, es]   \n",
       "16                           [es, es, es, es, es, es]   \n",
       "17                               [es, es, es, es, es]   \n",
       "18               [es, es, es, es, es, es, es, es, es]   \n",
       "19                       [es, es, es, es, es, es, es]   \n",
       "20                                   [es, es, es, es]   \n",
       "21                           [es, es, es, es, es, es]   \n",
       "22       [es, es, es, es, es, es, es, es, es, es, es]   \n",
       "23                               [es, es, es, es, es]   \n",
       "24                       [es, es, es, es, es, es, es]   \n",
       "25                               [es, es, es, es, es]   \n",
       "26                   [es, es, es, es, es, es, es, es]   \n",
       "27                               [es, es, es, es, es]   \n",
       "28                               [es, es, es, es, es]   \n",
       "29                               [es, es, es, es, es]   \n",
       "30                               [es, es, es, es, es]   \n",
       "31                       [es, es, es, es, es, es, es]   \n",
       "32                           [es, es, es, es, es, es]   \n",
       "33                                   [es, es, es, es]   \n",
       "34                               [es, es, es, es, es]   \n",
       "35                               [es, es, es, es, es]   \n",
       "36                                   [es, es, es, es]   \n",
       "37                           [es, es, es, es, es, es]   \n",
       "38  [es, es, es, es, es, es, es, es, es, es, es, e...   \n",
       "39  [es, es, es, es, es, es, es, es, es, es, es, e...   \n",
       "40                   [es, es, es, es, es, es, es, es]   \n",
       "41                               [es, es, es, es, es]   \n",
       "42                                   [es, es, es, es]   \n",
       "43                               [es, es, es, es, es]   \n",
       "44                   [es, es, es, es, es, es, es, es]   \n",
       "45                           [es, es, es, es, es, es]   \n",
       "46                                   [es, es, es, es]   \n",
       "47       [es, es, es, es, es, es, es, es, es, es, es]   \n",
       "48                               [es, es, es, es, es]   \n",
       "49                   [es, es, es, es, es, es, es, es]   \n",
       "\n",
       "                                                spans  \\\n",
       "0                          [LOC: Algarrobo ( Chile )]   \n",
       "1                                 [PER: W. G. Sebald]   \n",
       "2                                 [PER: Tamás Faragó]   \n",
       "3        [ORG: Società Sportiva Virtus Lanciano 1924]   \n",
       "4                           [ORG: Houses of the Holy]   \n",
       "5                                       [LOC: Luanda]   \n",
       "6                             [PER: José Luis García]   \n",
       "7                            [LOC: Condado de Duplin]   \n",
       "8                         [LOC: São Pedro do Funchal]   \n",
       "9                                       [LOC: Huelva]   \n",
       "10                   [LOC: Departamento de Cajamarca]   \n",
       "11                          [ORG: Ejército del Norte]   \n",
       "12                      [ORG: FC Progresul București]   \n",
       "13  [LOC: San Francisco, LOC: California, LOC: Est...   \n",
       "14  [PER: Pedro de Alcántara Téllez-Girón y Beaufo...   \n",
       "15                                       [ORG: E.T .]   \n",
       "16                              [PER: Marion Bartoli]   \n",
       "17           [PER: Peter McNamara, PER: Paul McNamee]   \n",
       "18                [ORG: Lombard Street, LOC: Londres]   \n",
       "19                                  [ORG: Toronto FC]   \n",
       "20                [ORG: Estación de Madrid-Chamartín]   \n",
       "21                   [ORG: Niños Héroes ( estación )]   \n",
       "22  [ORG: Museo Nacional de Arqueología , Antropol...   \n",
       "23                 [ORG: Students in Free Enterprise]   \n",
       "24               [PER: Lope Díez de Aux y Armendáriz]   \n",
       "25                                      [LOC: Bausen]   \n",
       "26  [ORG: Estadio Pedro Marrero, LOC: La Habana, L...   \n",
       "27                                        [ORG: CBGB]   \n",
       "28                        [PER: Ángel ( Buffyverso )]   \n",
       "29                                   [LOC: Cacabelos]   \n",
       "30           [ORG: Revista Colombiana de Estadística]   \n",
       "31                      [LOC: Nueva Valencia del Rey]   \n",
       "32                       [LOC: Berlín, LOC: Alemania]   \n",
       "33                            [PER: Gala Éluard Dalí]   \n",
       "34              [LOC: Avenida Revolución ( Tijuana )]   \n",
       "35                                      [LOC: Paraná]   \n",
       "36                     [PER: Víctor González Reynoso]   \n",
       "37           [PER: Federico II Eugenio de Wurtemberg]   \n",
       "38                                    [LOC: Zaragoza]   \n",
       "39                         [LOC: Estados UnidosSerie]   \n",
       "40                           [PER: Luis I de Flandes]   \n",
       "41                            [ORG: Gossip ( banda )]   \n",
       "42                        [PER: Historieta en España]   \n",
       "43                                  [PER: Iván Brzić]   \n",
       "44               [ORG: Tsubasa : Reservoir Chronicle]   \n",
       "45                           [ORG: Ratonero de Praga]   \n",
       "46                                 [PER: John Taylor]   \n",
       "47                                [LOC: Buenos Aires]   \n",
       "48                     [LOC: Fuente el Saz de Jarama]   \n",
       "49             [ORG: Batman : The Brave and the Bold]   \n",
       "\n",
       "                                                 text  \n",
       "0                     REDIRECCIÓN Algarrobo ( Chile )  \n",
       "1                                        W. G. Sebald  \n",
       "2                 ' '' Entrenador / a '' Tamás Faragó  \n",
       "3   REDIRECCIÓN Società Sportiva Virtus Lanciano 1924  \n",
       "4                                  Houses of the Holy  \n",
       "5                              ** Luanda ( Embajada )  \n",
       "6                        REDIRECCIÓN José Luis García  \n",
       "7                          Condado de Duplin suroeste  \n",
       "8                    REDIRECCIÓN São Pedro do Funchal  \n",
       "9                    50px '' Huelva '' '146.173 hab .  \n",
       "10              REDIRECCIÓN Departamento de Cajamarca  \n",
       "11  Posteriormente se incorporó al Ejército del No...  \n",
       "12                 REDIRECCIÓN FC Progresul București  \n",
       "13      San Francisco , California , Estados Unidos .  \n",
       "14  ' '' Pedro de Alcántara Téllez-Girón y Beaufor...  \n",
       "15                                        `` E.T . ''  \n",
       "16                           ' '' Marion Bartoli '' '  \n",
       "17                      Peter McNamara - Paul McNamee  \n",
       "18  Anteriormente estaba situada en Lombard Street...  \n",
       "19               Actualmente juega en el Toronto FC .  \n",
       "20           REDIRECCIÓN Estación de Madrid-Chamartín  \n",
       "21              REDIRECCIÓN Niños Héroes ( estación )  \n",
       "22  REDIRECCIÓN Museo Nacional de Arqueología , An...  \n",
       "23            REDIRECCIÓN Students in Free Enterprise  \n",
       "24          REDIRECCIÓN Lope Díez de Aux y Armendáriz  \n",
       "25                                   ' '' Bausen '' '  \n",
       "26           Estadio Pedro Marrero , La Habana , Cuba  \n",
       "27                             el mítico local CBGB .  \n",
       "28                   REDIRECCIÓN Ángel ( Buffyverso )  \n",
       "29                                ' '' Cacabelos '' '  \n",
       "30      REDIRECCIÓN Revista Colombiana de Estadística  \n",
       "31                Así surgió Nueva Valencia del Rey .  \n",
       "32              Springer-Verlag , Berlín , Alemania .  \n",
       "33                       REDIRECCIÓN Gala Éluard Dalí  \n",
       "34                     Avenida Revolución ( Tijuana )  \n",
       "35                             Paraná ( 247.310 hab .  \n",
       "36                REDIRECCIÓN Víctor González Reynoso  \n",
       "37      REDIRECCIÓN Federico II Eugenio de Wurtemberg  \n",
       "38  Sin embargo , su padre le ordenó ir a Zaragoza...  \n",
       "39  Tallahassee]] , Estados UnidosSerie regular $ ...  \n",
       "40                    Su hijo fue Luis I de Flandes .  \n",
       "41                       REDIRECCIÓN Gossip ( banda )  \n",
       "42                   REDIRECCIÓN Historieta en España  \n",
       "43                                Iván Brzić ( 1-34 )  \n",
       "44        === En Tsubasa : Reservoir Chronicle '' ===  \n",
       "45                          '' Ratonero de Praga '' '  \n",
       "46                                 John Taylor - bajo  \n",
       "47  Para realizar sus estudios secundarios debió v...  \n",
       "48                            Fuente el Saz de Jarama  \n",
       "49                 Batman : The Brave and the Bold ''  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dataset = load_dataset(\"wikiann\", \"es\", split='train')\n",
    "df = dataset.to_pandas()\n",
    "df['text']=[\" \".join(i['tokens']) for i in df]\n",
    "df['text']=[\" \".join(i) for i in df['tokens']]\n",
    "df.pop('tokens')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasión, vamos a explorar un poco más las características del dataset a manera ilustrativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAG0CAYAAABue26rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAw5klEQVR4nO3deVxV1f7/8TeDHEA4BwcQEcQxDXFITfM6K0aEDd7K4VoZNqul2c/KuqU2YcM1G7XhpreuZWo53MwB58ohxxSn1JzKnBXQChXW748enm9HQDm4ALHX8/HYjzx7r7PXZ69zgjd79DHGGAEAAFjgW9oFAACAywfBAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAvAguzsbL344ouaM2dOaZeCItq+fbuGDx+urVu3lnYpQJlGsIBXhg8fLh8fnxLpq0OHDurQoYP79aJFi+Tj46MpU6aUSP9/5uPjo+HDhxe4fPDgwZowYYJatmxZIvXcddddqlGjRon09VdgjFFKSoqWLl2qunXrllod48ePl4+Pj3bt2lVife7atUs+Pj4aP358ifWJyxvB4i/s7A+xs1NgYKCioqKUmJioN954Q1lZWVb62bdvn4YPH65169ZZWd+lZtKkSZo2bZpmzZqlsLCw0i6n1G3atEnDhw8v0V+OF+vtt9/Wjz/+qAkTJsjXlx+LwMXwL+0CUPqeffZZ1axZU6dPn9b+/fu1aNEiDRo0SKNGjdKMGTPUqFEjd9t//vOfeuKJJ7xa/759+zRixAjVqFFDTZo0KfT75s6d61U/xem3336Tv3/e/12MMfrpp580a9YsVa9evRQqu/Rs2rRJI0aMUIcOHcrEXpU9e/bo6aef1owZMxQeHl7a5QBlHsECSkpKUvPmzd2vhw4dqgULFqhr16668cYbtXnzZgUFBUmS/P398/0Fa9Ovv/6q4OBgBQQEFGs/3ggMDMx3vo+PjwYPHlzC1cCG3NxcnTp1StWrV9exY8dKuxzgssE+P+SrU6dOevrpp7V7927997//dc/P7xyLtLQ0tWnTRmFhYQoJCVG9evX05JNPSvrjvIirr75akpSSkuI+7HL2eG6HDh0UHx+v1atXq127dgoODna/99xzLM7KycnRk08+qcjISJUvX1433nij9u7d69GmRo0auuuuu/K8N791/v777xo+fLiuuOIKBQYGqmrVqvr73/+uHTt2uNvkd47F2rVrlZSUJKfTqZCQEHXu3FnLly/3aHP2cNO3336rwYMHKzw8XOXLl1e3bt106NChPPXlZ9q0aYqPj1dgYKDi4+M1derUfNvl5uZq9OjRatCggQIDA1WlShXdf//9hf6luWXLFnXv3l3h4eEKCgpSvXr19NRTT7mX7969W/369VO9evUUFBSkSpUq6bbbbvM45DF+/HjddtttkqSOHTu6P+9Fixa528yaNUtt27ZV+fLlFRoaquTkZG3cuDFPPZMnT1ZcXJzHdud3bsnJkyf16KOPKiYmRg6HQ/Xq1dOrr76qcx/c7OPjowEDBmjChAlq0KCBHA6HZs+e7V7258+3MNsqSadPn9aIESNUt25dBQYGqlKlSmrTpo3S0tIuON4bN25Up06dFBQUpOjoaD3//PPKzc3Nt21hxyw/x48f1yOPPKIaNWrI4XAoOjpad955pw4fPlzge9avX6+77rpLtWrVUmBgoCIjI9W3b18dOXLEo11WVpYGDRrkXndERIS6dOmiNWvWeLRbsWKFrrvuOrlcLgUHB6t9+/b69ttvi7QuXPrYY4EC3XHHHXryySc1d+5c3Xvvvfm22bhxo7p27apGjRrp2WeflcPh0Pbt290/NK688ko9++yzeuaZZ3Tfffepbdu2kqS//e1v7nUcOXJESUlJ6tmzp26//XZVqVLlvHW98MIL8vHx0eOPP66DBw9q9OjRSkhI0Lp169x7VgorJydHXbt21fz589WzZ08NHDhQWVlZSktLU3p6umrXrl3gdrdt21ZOp1OPPfaYypUrp3fffVcdOnTQ4sWL85zE+dBDD6lChQoaNmyYdu3apdGjR2vAgAH67LPPzlvf3LlzdcsttyguLk6pqak6cuSIUlJSFB0dnaft/fffr/HjxyslJUUPP/ywdu7cqbfeektr167Vt99+q3LlyhXYz/r169W2bVuVK1dO9913n2rUqKEdO3bof//7n1544QVJ0sqVK7V06VL17NlT0dHR2rVrl8aMGaMOHTpo06ZNCg4OVrt27fTwww/rjTfe0JNPPqkrr7xSktz//fjjj9WnTx8lJibqpZde0q+//qoxY8aoTZs2Wrt2rTs0zJw5Uz169FDDhg2VmpqqY8eO6e6771a1atU86jbG6MYbb9TChQt19913q0mTJpozZ46GDBmin3/+Wa+99ppH+wULFmjSpEkaMGCAKleuXOChmsJsq/RH0E5NTdU999yjFi1aKDMzU6tWrdKaNWvUpUuXAsd7//796tixo86cOaMnnnhC5cuX13vvvZfv97ewY5afEydOqG3bttq8ebP69u2rpk2b6vDhw5oxY4Z++uknVa5cOd/3paWl6ccff1RKSooiIyO1ceNGvffee9q4caOWL1/u/uPigQce0JQpUzRgwADFxcXpyJEj+uabb7R582Y1bdrUPeZJSUlq1qyZhg0bJl9fX40bN06dOnXS119/rRYtWhR6XSgjDP6yxo0bZySZlStXFtjG5XKZq666yv162LBh5s9fm9dee81IMocOHSpwHStXrjSSzLhx4/Isa9++vZFkxo4dm++y9u3bu18vXLjQSDLVqlUzmZmZ7vmTJk0ykszrr7/unhcbG2v69OlzwXV++OGHRpIZNWpUnra5ubnuf0syw4YNc7+++eabTUBAgNmxY4d73r59+0xoaKhp166de97ZMU5ISPBY3yOPPGL8/PzM8ePH8/T7Z02aNDFVq1b1aDd37lwjycTGxrrnff3110aSmTBhgsf7Z8+ene/8c7Vr186Ehoaa3bt3FzgGv/76a573LVu2zEgyH330kXve5MmTjSSzcOFCj7ZZWVkmLCzM3HvvvR7z9+/fb1wul8f8hg0bmujoaJOVleWet2jRojzbPW3aNCPJPP/88x7rvPXWW42Pj4/Zvn27e54k4+vrazZu3JhnO879fAu7rY0bNzbJycl52l7IoEGDjCSzYsUK97yDBw8al8tlJJmdO3caY7wbs/w888wzRpL54osv8iw7+9nu3Lkzz/+f+W3/p59+aiSZJUuWuOe5XC7Tv3//AvvPzc01devWNYmJiXm+SzVr1jRdunQp9LpQdnAoBOcVEhJy3qtDzl4FMX369AJ3416Iw+FQSkpKodvfeeedCg0Ndb++9dZbVbVqVX311Vde9/3555+rcuXKeuihh/IsK+iy2pycHM2dO1c333yzatWq5Z5ftWpV/eMf/9A333yjzMxMj/fcd999Hutr27atcnJytHv37gJr++WXX7Ru3Tr16dNHLpfLPb9Lly6Ki4vzaDt58mS5XC516dJFhw8fdk/NmjVTSEiIFi5cWGA/hw4d0pIlS9S3b988J6D+ueY//zV9+vRpHTlyRHXq1FFYWFihdlenpaXp+PHj6tWrl0eNfn5+atmypbvGffv2acOGDbrzzjsVEhLifn/79u3VsGFDj3V+9dVX8vPz08MPP+wx/9FHH5UxRrNmzfKY3759+zxjl5/CbmtYWJg2btyobdu2XXCd59Z9zTXXuP9al6Tw8HD17t3bo11hx6wgn3/+uRo3bqxu3brlWXa+y8b/vP2///67Dh8+rGuuuUaS8mz/ihUrtG/fvnzXs27dOm3btk3/+Mc/dOTIEXf9J0+eVOfOnbVkyRL3z40LrQtlB8EC53XixAmPX+Ln6tGjh1q3bq177rlHVapUUc+ePTVp0iSvQka1atW8OlHz3PsM+Pj4qE6dOkW6vHHHjh2qV6+eVyekHjp0SL/++qvq1auXZ9mVV16p3NzcPOd8nPsLu0KFCpJ03vMfzoaO/O6rcG7f27ZtU0ZGhiIiIhQeHu4xnThxQgcPHiywnx9//FGSFB8fX2Ab6Y8rY5555hn3uQyVK1dWeHi4jh8/royMjPO+92yN0h/n75xb49y5c901nt3uOnXq5FnHufN2796tqKioPN/Rs4dezg1uNWvWvGCd3mzrs88+q+PHj+uKK65Qw4YNNWTIEK1fv/6C69+9e3ehP1fpwmNWkB07dlzwc83P0aNHNXDgQFWpUkVBQUEKDw93j92ft//ll19Wenq6YmJi1KJFCw0fPtz9ffpz/X369MlT/wcffKDs7Gz3+i60LpQdnGOBAv3000/KyMjI9wf8WUFBQVqyZIkWLlyomTNnavbs2frss8/UqVMnzZ07V35+fhfsx9vzIgrjfHsbClOTbQX1ac45wbCocnNzFRERoQkTJuS73MZllA899JDGjRunQYMGqVWrVnK5XPLx8VHPnj0LFSTPtvn4448VGRmZZ3lxX20kFf67VthtbdeunXbs2KHp06dr7ty5+uCDD/Taa69p7Nixuueeey663tIas+7du2vp0qUaMmSImjRpopCQEOXm5uq6667z2P7u3burbdu2mjp1qubOnatXXnlFL730kr744gslJSW5277yyisFXmp+dq/UhdaFsoNggQJ9/PHHkqTExMTztvP19VXnzp3VuXNnjRo1Si+++KKeeuopLVy4UAkJCdbv1HnubmdjjLZv3+5xv40KFSro+PHjed67e/duj8MXtWvX1ooVK3T69Onzntz4Z+Hh4QoODs731s9btmyRr6+vYmJiCrk1BYuNjZWUd3sl5em7du3amjdvnlq3bu11UDs7Hunp6edtN2XKFPXp00f/+te/3PN+//33PONc0Od99kTYiIgIJSQkFNjP2e3evn17nmXnzouNjdW8efOUlZXlsddiy5YtHuvyVmG3VZIqVqyolJQUpaSk6MSJE2rXrp2GDx9+3mARGxtb6M9VuvCYFaR27doX/FzPdezYMc2fP18jRozQM888455f0OGeqlWrql+/furXr58OHjyopk2b6oUXXlBSUpK7fqfTWaj6z7culB0cCkG+FixYoOeee041a9bMc9z3z44ePZpn3tm/TLKzsyVJ5cuXl6R8fygXxUcffeRx3seUKVP0yy+/ePzwqV27tpYvX65Tp06553355Zd5DlHccsstOnz4sN566608/RS0N8HPz0/XXnutpk+f7nH45cCBA/rkk0/Upk0bOZ3Oom6eW9WqVdWkSRP95z//8dj9nJaWpk2bNnm07d69u3JycvTcc8/lWc+ZM2fOO/bh4eFq166dPvzwQ+3Zs8dj2Z/HwM/PL8+YvPnmm8rJyfGYV9DnnZiYKKfTqRdffFGnT5/OU8fZy2+joqIUHx+vjz76SCdOnHAvX7x4sTZs2ODxnuuvv145OTl5Pr/XXntNPj4+Rf6FVNhtPffyy5CQENWpU8f93S/I9ddfr+XLl+u7775zzzt06FCePU6FHbOC3HLLLfr+++/zvUT5fN/v/JaPHj3a43VOTk6eQ2ARERGKiopyb3+zZs1Uu3Ztvfrqqx6f5bn1F2ZdKDvYYwHNmjVLW7Zs0ZkzZ3TgwAEtWLBAaWlpio2N1YwZMwq8OZT0xzHmJUuWKDk5WbGxsTp48KDeeecdRUdHq02bNpL++CUfFhamsWPHKjQ0VOXLl1fLli0Lfbz7XBUrVlSbNm2UkpKiAwcOaPTo0apTp47HJbH33HOPpkyZouuuu07du3fXjh079N///jfP5aN33nmnPvroIw0ePFjfffed2rZtq5MnT2revHnq16+fbrrppnxreP7559337+jXr5/8/f317rvvKjs7Wy+//HKRtis/qampSk5OVps2bdS3b18dPXpUb775pho0aODxg7p9+/a6//77lZqaqnXr1unaa69VuXLltG3bNk2ePFmvv/66br311gL7eeONN9SmTRs1bdpU9913n2rWrKldu3Zp5syZ7luxd+3aVR9//LFcLpfi4uK0bNkyzZs3T5UqVfJYV5MmTeTn56eXXnpJGRkZcjgc6tSpkyIiIjRmzBjdcccdatq0qXr27Knw8HDt2bNHM2fOVOvWrd0B4cUXX9RNN92k1q1bKyUlRceOHdNbb72l+Ph4j+2+4YYb1LFjRz311FPatWuXGjdurLlz52r69OkaNGhQgZcLX0hhtzUuLk4dOnRQs2bNVLFiRa1atcp9yeT5PPbYY/r444913XXXaeDAge7LTWNjYz3O0XA6nYUes/wMGTJEU6ZM0W233aa+ffuqWbNmOnr0qGbMmKGxY8eqcePGed7jdDrVrl07vfzyyzp9+rSqVaumuXPnaufOnR7tsrKyFB0drVtvvVWNGzdWSEiI5s2bp5UrV7r39Pj6+uqDDz5QUlKSGjRooJSUFFWrVk0///yzFi5cKKfTqf/973+FWhfKkFK7HgWl7uylkGengIAAExkZabp06WJef/11j0s6zzr3ctP58+ebm266yURFRZmAgAATFRVlevXqZX744QeP902fPt3ExcUZf39/j0vb2rdvbxo0aJBvfQVdbvrpp5+aoUOHmoiICBMUFGSSk5PzXCZpjDH/+te/TLVq1YzD4TCtW7c2q1atyrNOY/649O2pp54yNWvWNOXKlTORkZHm1ltv9biUVOdcjmiMMWvWrDGJiYkmJCTEBAcHm44dO5qlS5fmO8bnXtJ7dlvOvSQzP59//rm58sorjcPhMHFxceaLL74wffr08bjs8qz33nvPNGvWzAQFBZnQ0FDTsGFD89hjj5l9+/ZdsJ/09HTTrVs3ExYWZgIDA029evXM008/7V5+7Ngxk5KSYipXrmxCQkJMYmKi2bJlS76X9r7//vumVq1axs/PL892Lly40CQmJhqXy2UCAwNN7dq1zV133WVWrVrlsY6JEyea+vXrG4fDYeLj482MGTPMLbfcYurXr+/RLisryzzyyCMmKirKlCtXztStW9e88sorHpc3GvPHZ1jQ5Yznfr6F3dbnn3/etGjRwoSFhZmgoCBTv35988ILL5hTp05dcLzXr19v2rdvbwIDA021atXMc889Z/797397XG7q7Zjl58iRI2bAgAGmWrVqJiAgwERHR5s+ffqYw4cPG2Pyv9z0p59+cn8XXC6Xue2228y+ffs8xik7O9sMGTLENG7c2ISGhpry5cubxo0bm3feeSdPDWvXrjV///vfTaVKlYzD4TCxsbGme/fuZv78+V6vC5c+H2MsnT0GAMWsSZMmCg8PL9SdLQGUDs6xAHDJOX36tM6cOeMxb9GiRfr+++/zvc07gEsHeywAXHJ27dqlhIQE3X777YqKitKWLVs0duxYuVwupaen5znXAcClg5M3AVxyKlSooGbNmumDDz7QoUOHVL58eSUnJ2vkyJGECuASxx4LAABgDedYAAAAawgWAADAGoIFAACwpsRP3szNzdW+ffsUGhpq/RkSAACgeBhjlJWVpaioKPn6FrxfosSDxb59+6w8oAkAAJS8vXv3Kjo6usDlJR4szj6BcO/evVYe1AQAAIpfZmamYmJiPJ4knJ8SDxZnD384nU6CBQAAZcyFTmPg5E0AAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYU+K39D4rftgc+TqCS6t7eGHXyOTSLgEAUEawxwIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgjdfB4ueff9btt9+uSpUqKSgoSA0bNtSqVauKozYAAFDGeHXnzWPHjql169bq2LGjZs2apfDwcG3btk0VKlQorvoAAEAZ4lWweOmllxQTE6Nx48a559WsWdN6UQAAoGzy6lDIjBkz1Lx5c912222KiIjQVVddpffff/+878nOzlZmZqbHBAAALk9eBYsff/xRY8aMUd26dTVnzhw9+OCDevjhh/Wf//ynwPekpqbK5XK5p5iYmIsuGgAAXJp8jDGmsI0DAgLUvHlzLV261D3v4Ycf1sqVK7Vs2bJ835Odna3s7Gz368zMTMXExChm0CSeblpG8HRTAEBmZqZcLpcyMjLkdDoLbOfVHouqVasqLi7OY96VV16pPXv2FPgeh8Mhp9PpMQEAgMuTV8GidevW2rp1q8e8H374QbGxsVaLAgAAZZNXweKRRx7R8uXL9eKLL2r79u365JNP9N5776l///7FVR8AAChDvAoWV199taZOnapPP/1U8fHxeu655zR69Gj17t27uOoDAABliFf3sZCkrl27qmvXrsVRCwAAKON4VggAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsIZgAQAArPH6clNb0kckcntvAAAuM+yxAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANf6l1XH8sDnydQSXVvdl1q6RyaVdAgAABWKPBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwhmABAACsIVgAAABrCBYAAMAar4LF8OHD5ePj4zHVr1+/uGoDAABljNd33mzQoIHmzZv3fyvwL7WbdwIAgEuM16nA399fkZGRxVELAAAo47w+x2Lbtm2KiopSrVq11Lt3b+3Zs+e87bOzs5WZmekxAQCAy5NXwaJly5YaP368Zs+erTFjxmjnzp1q27atsrKyCnxPamqqXC6Xe4qJibnoogEAwKXJxxhjivrm48ePKzY2VqNGjdLdd9+db5vs7GxlZ2e7X2dmZiomJkYxgybxdNMi4OmmAIDSkJmZKZfLpYyMDDmdzgLbXdSZl2FhYbriiiu0ffv2Ats4HA45HI6L6QYAAJQRF3UfixMnTmjHjh2qWrWqrXoAAEAZ5lWw+H//7/9p8eLF2rVrl5YuXapu3brJz89PvXr1Kq76AABAGeLVoZCffvpJvXr10pEjRxQeHq42bdpo+fLlCg8PL676AABAGeJVsJg4cWJx1QEAAC4DPCsEAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANZc1C29L0b6iMTz3mscAACUPeyxAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1viXVsfxw+bI1xFcWt0Dl6xdI5NLuwQAKDL2WAAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwhmABAACsuahgMXLkSPn4+GjQoEGWygEAAGVZkYPFypUr9e6776pRo0Y26wEAAGVYkYLFiRMn1Lt3b73//vuqUKGC7ZoAAEAZVaRg0b9/fyUnJyshIcF2PQAAoAzz+iFkEydO1Jo1a7Ry5cpCtc/OzlZ2drb7dWZmprddAgCAMsKrPRZ79+7VwIEDNWHCBAUGBhbqPampqXK5XO4pJiamSIUCAIBLn48xxhS28bRp09StWzf5+fm55+Xk5MjHx0e+vr7Kzs72WCblv8ciJiZGMYMm8dh0IB88Nh3ApSgzM1Mul0sZGRlyOp0FtvPqUEjnzp21YcMGj3kpKSmqX7++Hn/88TyhQpIcDoccDoc33QAAgDLKq2ARGhqq+Ph4j3nly5dXpUqV8swHAAB/Pdx5EwAAWOP1VSHnWrRokYUyAADA5YA9FgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwhmABAACsuej7WBRV+ojE895rHAAAlD3ssQAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANb4l1bH8cPmyNcRXFrdl5pdI5NLuwQAAIoNeywAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1ngVLMaMGaNGjRrJ6XTK6XSqVatWmjVrVnHVBgAAyhivgkV0dLRGjhyp1atXa9WqVerUqZNuuukmbdy4sbjqAwAAZYhXt/S+4YYbPF6/8MILGjNmjJYvX64GDRpYLQwAAJQ9RX5WSE5OjiZPnqyTJ0+qVatWBbbLzs5Wdna2+3VmZmZRuwQAAJc4r0/e3LBhg0JCQuRwOPTAAw9o6tSpiouLK7B9amqqXC6Xe4qJibmoggEAwKXL62BRr149rVu3TitWrNCDDz6oPn36aNOmTQW2Hzp0qDIyMtzT3r17L6pgAABw6fL6UEhAQIDq1KkjSWrWrJlWrlyp119/Xe+++26+7R0OhxwOx8VVCQAAyoSLvo9Fbm6uxzkUAADgr8urPRZDhw5VUlKSqlevrqysLH3yySdatGiR5syZU1z1AQCAMsSrYHHw4EHdeeed+uWXX+RyudSoUSPNmTNHXbp0Ka76AABAGeJVsPj3v/9dXHUAAIDLAM8KAQAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGBNkR+bfrHSRyTK6XSWVvcAAKAYsMcCAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABY419aHccPmyNfR3BpdY9StmtkcmmXAAAoBuyxAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFjjVbBITU3V1VdfrdDQUEVEROjmm2/W1q1bi6s2AABQxngVLBYvXqz+/ftr+fLlSktL0+nTp3Xttdfq5MmTxVUfAAAoQ7y6pffs2bM9Xo8fP14RERFavXq12rVrZ7UwAABQ9lzUs0IyMjIkSRUrViywTXZ2trKzs92vMzMzL6ZLAABwCSvyyZu5ubkaNGiQWrdurfj4+ALbpaamyuVyuaeYmJiidgkAAC5xRQ4W/fv3V3p6uiZOnHjedkOHDlVGRoZ72rt3b1G7BAAAl7giHQoZMGCAvvzySy1ZskTR0dHnbetwOORwOIpUHAAAKFu8ChbGGD300EOaOnWqFi1apJo1axZXXQAAoAzyKlj0799fn3zyiaZPn67Q0FDt379fkuRyuRQUFFQsBQIAgLLDq3MsxowZo4yMDHXo0EFVq1Z1T5999llx1QcAAMoQrw+FAAAAFIRnhQAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAmot6uunFSB+RKKfTWVrdAwCAYsAeCwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWONfWh3HD5sjX0dwaXV/Sds1Mrm0SwAAoEjYYwEAAKwhWAAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwxutgsWTJEt1www2KioqSj4+Ppk2bVgxlAQCAssjrYHHy5Ek1btxYb7/9dnHUAwAAyjCvb+mdlJSkpKSk4qgFAACUccX+rJDs7GxlZ2e7X2dmZhZ3lwAAoJQU+8mbqampcrlc7ikmJqa4uwQAAKWk2IPF0KFDlZGR4Z727t1b3F0CAIBSUuyHQhwOhxwOR3F3AwAALgHcxwIAAFjj9R6LEydOaPv27e7XO3fu1Lp161SxYkVVr17danEAAKBs8TpYrFq1Sh07dnS/Hjx4sCSpT58+Gj9+vLXCAABA2eN1sOjQoYOMMcVRCwAAKOM4xwIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hT7Lb0Lkj4iUU6ns7S6BwAAxYA9FgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwhmABAACsIVgAAABrCBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsIZgAQAArCFYAAAAawgWAADAGoIFAACwhmABAACsIVgAAABrCBYAAMAaggUAALCGYAEAAKwhWAAAAGsIFgAAwBqCBQAAsMa/tDqOHzZHvo7g0uoeAIDLzq6RyaVdAnssAACAPQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYUKVi8/fbbqlGjhgIDA9WyZUt99913tusCAABlkNfB4rPPPtPgwYM1bNgwrVmzRo0bN1ZiYqIOHjxYHPUBAIAyxOtgMWrUKN17771KSUlRXFycxo4dq+DgYH344YfFUR8AAChDvAoWp06d0urVq5WQkPB/K/D1VUJCgpYtW5bve7Kzs5WZmekxAQCAy5NXweLw4cPKyclRlSpVPOZXqVJF+/fvz/c9qampcrlc7ikmJqbo1QIAgEtasV8VMnToUGVkZLinvXv3FneXAACglHj12PTKlSvLz89PBw4c8Jh/4MABRUZG5vseh8Mhh8NR9AoBAECZ4dUei4CAADVr1kzz5893z8vNzdX8+fPVqlUr68UBAICyxas9FpI0ePBg9enTR82bN1eLFi00evRonTx5UikpKcVRHwAAKEO8DhY9evTQoUOH9Mwzz2j//v1q0qSJZs+eneeETgAA8NfjdbCQpAEDBmjAgAG2awEAAGUczwoBAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDVFutzUhvQRiXI6naXVPQAAKAbssQAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1hAsAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGBNiT8rxBgjScrMzCzprgEAQBGd/b199vd4QUo8WBw5ckSSFBMTU9JdAwCAi5SVlSWXy1Xg8hIPFhUrVpQk7dmz57yFwXuZmZmKiYnR3r17eXKsZYxt8WFsiw9jW3z+imNrjFFWVpaioqLO267Eg4Wv7x+ndbhcrr/Mh1HSnE4nY1tMGNviw9gWH8a2+PzVxrYwOwQ4eRMAAFhDsAAAANaUeLBwOBwaNmyYHA5HSXd92WNsiw9jW3wY2+LD2BYfxrZgPuZC140AAAAUEodCAACANQQLAABgDcECAABYQ7AAAADWlGiwePvtt1WjRg0FBgaqZcuW+u6770qy+0vOkiVLdMMNNygqKko+Pj6aNm2ax3JjjJ555hlVrVpVQUFBSkhI0LZt2zzaHD16VL1795bT6VRYWJjuvvtunThxwqPN+vXr1bZtWwUGBiomJkYvv/xynlomT56s+vXrKzAwUA0bNtRXX31lfXtLUmpqqq6++mqFhoYqIiJCN998s7Zu3erR5vfff1f//v1VqVIlhYSE6JZbbtGBAwc82uzZs0fJyckKDg5WRESEhgwZojNnzni0WbRokZo2bSqHw6E6depo/Pjxeeq5nL77Y8aMUaNGjdw3BmrVqpVmzZrlXs642jNy5Ej5+Pho0KBB7nmMb9EMHz5cPj4+HlP9+vXdyxlXi0wJmThxogkICDAffvih2bhxo7n33ntNWFiYOXDgQEmVcMn56quvzFNPPWW++OILI8lMnTrVY/nIkSONy+Uy06ZNM99//7258cYbTc2aNc1vv/3mbnPdddeZxo0bm+XLl5uvv/7a1KlTx/Tq1cu9PCMjw1SpUsX07t3bpKenm08//dQEBQWZd999193m22+/NX5+fubll182mzZtMv/85z9NuXLlzIYNG4p9DIpLYmKiGTdunElPTzfr1q0z119/valevbo5ceKEu80DDzxgYmJizPz5882qVavMNddcY/72t7+5l585c8bEx8ebhIQEs3btWvPVV1+ZypUrm6FDh7rb/PjjjyY4ONgMHjzYbNq0ybz55pvGz8/PzJ49293mcvvuz5gxw8ycOdP88MMPZuvWrebJJ5805cqVM+np6cYYxtWW7777ztSoUcM0atTIDBw40D2f8S2aYcOGmQYNGphffvnFPR06dMi9nHG1p8SCRYsWLUz//v3dr3NyckxUVJRJTU0tqRIuaecGi9zcXBMZGWleeeUV97zjx48bh8NhPv30U2OMMZs2bTKSzMqVK91tZs2aZXx8fMzPP/9sjDHmnXfeMRUqVDDZ2dnuNo8//ripV6+e+3X37t1NcnKyRz0tW7Y0999/v9VtLE0HDx40kszixYuNMX+MZbly5czkyZPdbTZv3mwkmWXLlhlj/gh+vr6+Zv/+/e42Y8aMMU6n0z2ejz32mGnQoIFHXz169DCJiYnu13+F736FChXMBx98wLhakpWVZerWrWvS0tJM+/bt3cGC8S26YcOGmcaNG+e7jHG1q0QOhZw6dUqrV69WQkKCe56vr68SEhK0bNmykiihzNm5c6f279/vMWYul0stW7Z0j9myZcsUFham5s2bu9skJCTI19dXK1ascLdp166dAgIC3G0SExO1detWHTt2zN3mz/2cbXM5fTYZGRmS/u8heKtXr9bp06c9trt+/fqqXr26x/g2bNhQVapUcbdJTExUZmamNm7c6G5zvrG73L/7OTk5mjhxok6ePKlWrVoxrpb0799fycnJecaA8b0427ZtU1RUlGrVqqXevXtrz549khhX20okWBw+fFg5OTkeH4gkValSRfv37y+JEsqcs+NyvjHbv3+/IiIiPJb7+/urYsWKHm3yW8ef+yiozeXy2eTm5mrQoEFq3bq14uPjJf2xzQEBAQoLC/Noe+74FnXsMjMz9dtvv1223/0NGzYoJCREDodDDzzwgKZOnaq4uDjG1YKJEydqzZo1Sk1NzbOM8S26li1bavz48Zo9e7bGjBmjnTt3qm3btsrKymJcLSvxp5sCJa1///5KT0/XN998U9qlXDbq1aundevWKSMjQ1OmTFGfPn20ePHi0i6rzNu7d68GDhyotLQ0BQYGlnY5l5WkpCT3vxs1aqSWLVsqNjZWkyZNUlBQUClWdvkpkT0WlStXlp+fX54zbA8cOKDIyMiSKKHMOTsu5xuzyMhIHTx40GP5mTNndPToUY82+a3jz30U1OZy+GwGDBigL7/8UgsXLlR0dLR7fmRkpE6dOqXjx497tD93fIs6dk6nU0FBQZftdz8gIEB16tRRs2bNlJqaqsaNG+v1119nXC/S6tWrdfDgQTVt2lT+/v7y9/fX4sWL9cYbb8jf319VqlRhfC0JCwvTFVdcoe3bt/O9taxEgkVAQICaNWum+fPnu+fl5uZq/vz5atWqVUmUUObUrFlTkZGRHmOWmZmpFStWuMesVatWOn78uFavXu1us2DBAuXm5qply5buNkuWLNHp06fdbdLS0lSvXj1VqFDB3ebP/ZxtU5Y/G2OMBgwYoKlTp2rBggWqWbOmx/JmzZqpXLlyHtu9detW7dmzx2N8N2zY4BHe0tLS5HQ6FRcX525zvrH7q3z3c3NzlZ2dzbhepM6dO2vDhg1at26de2revLl69+7t/jfja8eJEye0Y8cOVa1ale+tbSV1lujEiRONw+Ew48ePN5s2bTL33XefCQsL8zjD9q8mKyvLrF271qxdu9ZIMqNGjTJr1641u3fvNsb8cblpWFiYmT59ulm/fr256aab8r3c9KqrrjIrVqww33zzjalbt67H5abHjx83VapUMXfccYdJT083EydONMHBwXkuN/X39zevvvqq2bx5sxk2bFiZv9z0wQcfNC6XyyxatMjj8rJff/3V3eaBBx4w1atXNwsWLDCrVq0yrVq1Mq1atXIvP3t52bXXXmvWrVtnZs+ebcLDw/O9vGzIkCFm8+bN5u2338738rLL6bv/xBNPmMWLF5udO3ea9evXmyeeeML4+PiYuXPnGmMYV9v+fFWIMYxvUT366KNm0aJFZufOnebbb781CQkJpnLlyubgwYPGGMbVphILFsYY8+abb5rq1aubgIAA06JFC7N8+fKS7P6Ss3DhQiMpz9SnTx9jzB+XnD799NOmSpUqxuFwmM6dO5utW7d6rOPIkSOmV69eJiQkxDidTpOSkmKysrI82nz//femTZs2xuFwmGrVqpmRI0fmqWXSpEnmiiuuMAEBAaZBgwZm5syZxbbdJSG/cZVkxo0b527z22+/mX79+pkKFSqY4OBg061bN/PLL794rGfXrl0mKSnJBAUFmcqVK5tHH33UnD592qPNwoULTZMmTUxAQICpVauWRx9nXU7f/b59+5rY2FgTEBBgwsPDTefOnd2hwhjG1bZzgwXjWzQ9evQwVatWNQEBAaZatWqmR48eZvv27e7ljKs9PDYdAABYw7NCAACANQQLAABgDcECAABYQ7AAAADWECwAAIA1BAsAAGANwQIAAFhDsAAAANYQLAAAgDUECwAAYA3BAgAAWEOwAAAA1vx/kZJ8I/DOwkIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df_cat=pd.DataFrame(df['ner_tags'])\n",
    "all_cats=[]\n",
    "for cat in df_cat['ner_tags']: \n",
    "    all_cats.extend(cat)\n",
    "\n",
    "pd.Series(Counter(all_cats)).sort_index().plot.barh()\n",
    "plt.title('Distribución de categorías de clases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que es un dataset balanceado.\n",
    "\n",
    "Ahora observemos la dispersión de las palabras por cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto más corto: 3\n",
      "Texto más largo: 64\n",
      "Longitud promedio: 6.46\n",
      "Mediana: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Calcula la longitud de cada texto en número de tokens (palabras)\n",
    "text_lengths = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"Texto más corto: {text_lengths.min()}\")\n",
    "print(f\"Texto más largo: {text_lengths.max()}\")\n",
    "print(f\"Longitud promedio: {text_lengths.mean():.2f}\")\n",
    "print(f\"Mediana: {text_lengths.median()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiendo el Tokenizer\n",
    "\n",
    "Como la idea en este notebook es la de re-utilizar modelos pre-entrenados, algo a tener en cuenta es que para que esto funcione correctamente, debemos **siempre** utilizar el mismo tokenizador que se usó para entrenar el modelo. Recordemos que el tokenizador asigna un código a cada token del vocabulario, y durante la creación de los embeddings, el modelo asume esto como entrada, por lo que su usamos otro tokenizador, el modelo va a ser incapaz de derivar las relaciones semánticas apropiadas.\n",
    "\n",
    "Para esta tarea, haremos uso de un modelo BERT pre-entrenado en corpus del idioma español. El modelo puede ser encontrado [aquí](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased), es un modelo entrenado por el [Departamento de Ciencias de la Computación de la Universidad de Chile](https://www.dcc.uchile.cl), el cual según los autores, fue entrenado en un gran corpus de idioma español por lo que resulta un buen candidato para la tarea en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sometamos a prueba el tokenizador con la misma frase del notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hola',\n",
       " 'mundo',\n",
       " '!',\n",
       " '!',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = '[PAD]'\n",
    "tokenizer(\"hola mundo!!\", max_length=10, truncation=True, padding='max_length').tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo interesante, este tokenizador, por lo menos para las palabras de esta frase de prueba, no separa en tokens distintos estas palabras, esto es justamente la razón por la cual no deberíamos usar un tokenizador diferente con un modelo pre-entrenado, habríamos obtenido tokens diferentes y el modelo no lograría interpretar la semantica como se espera.\n",
    "\n",
    "Ahora, observemos su vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos $31002$ tokens, es una cantidad inferior que el modelo manual que intentamos en la lección anterior, pero lo suficientemente amplio para una tarea de NLP.\n",
    "\n",
    "Ahora, observemos otros parámetros del tokenizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, observamos que el tokenizador por defecto maneja un tamaño de secuencia de $512$, Que para nuestro dataset es bastante mas de lo necesario, por lo tanto, ninguna de las secuencias de entrada será truncada. Observando sus salidas, las cuales serán las entradas a nuestro modelo. Como ya debemos saber, `input_ids` son los indices de los tokens y `attention_mask` es la máscara de atención cuando tenemos tokens irrelevantes (como el padding) en la cadena.\n",
    "\n",
    "## Usando un modelo BERT pre-entrenado sencillo\n",
    "\n",
    "![](../assets/bert-architecture.png)\n",
    "![](../assets/bert-tokenization.png)\n",
    "Primero, vamos a probar con un modelo pre-entrenado sin mayor modificación a la capa de clasificación. Hugging Face ofrece una clase utilitaria para inicializar el modelo en modo de clasificación de tokens, lo cual hará que convenientemente tengamos una capa o cabeza de clasificación de tokens en entidades dentro del modelo, justo con la cantidad de clases que definamos.\n",
    "\n",
    "Recordemos que el modelo y el tokenizador deben pertenecer al mismo \"paquete\", por lo que invocamos a `from_pretrained` con el mismo id que al tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Input Shapes & Types:\n",
      "{'input_ids': (torch.Size([1, 10]), torch.int64), 'token_type_ids': (torch.Size([1, 10]), torch.int64), 'attention_mask': (torch.Size([1, 10]), torch.int64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
      "================================================================================================================================================================\n",
      "BertForTokenClassification                                   [1, 10]                   [1, 10, 7]                --                        Partial\n",
      "├─BertModel: 1-1                                             [1, 10]                   [1, 10, 768]              --                        False\n",
      "│    └─BertEmbeddings: 2-1                                   --                        [1, 10, 768]              --                        False\n",
      "│    │    └─Embedding: 3-1                                   [1, 10]                   [1, 10, 768]              (23,809,536)              False\n",
      "│    │    └─Embedding: 3-2                                   [1, 10]                   [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Embedding: 3-3                                   [1, 10]                   [1, 10, 768]              (393,216)                 False\n",
      "│    │    └─LayerNorm: 3-4                                   [1, 10, 768]              [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Dropout: 3-5                                     [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "│    └─BertEncoder: 2-2                                      [1, 10, 768]              [1, 10, 768]              --                        False\n",
      "│    │    └─ModuleList: 3-6                                  --                        --                        (85,054,464)              False\n",
      "├─Dropout: 1-2                                               [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "├─Linear: 1-3                                                [1, 10, 768]              [1, 10, 7]                5,383                     True\n",
      "================================================================================================================================================================\n",
      "Total params: 109,265,671\n",
      "Trainable params: 5,383\n",
      "Non-trainable params: 109,260,288\n",
      "Total mult-adds (Units.MEGABYTES): 109.27\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 8.36\n",
      "Params size (MB): 437.06\n",
      "Estimated Total Size (MB): 445.42\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "# Ejemplo de texto\n",
    "inputs = tokenizer(\"Hola Mundo!!!\", \n",
    "                   max_length=10, \n",
    "                   truncation=True, \n",
    "                   padding='max_length', \n",
    "                   return_tensors='pt')\n",
    "\n",
    "print(\"Input Shapes & Types:\")\n",
    "print({k: (v.shape, v.dtype) for k, v in inputs.items()})\n",
    "\n",
    "# Definición de etiquetas (ejemplo NER: O, PER, LOC, ORG)\n",
    "label2id = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-ORG\": 3, \"I-ORG\": 4, \"B-LOC\": 5, \"I-LOC\": 6}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Cargamos modelo para token classification (NER)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "# Congelamos pesos del modelo base\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# torchinfo necesita los inputs esperados: input_ids y attention_mask\n",
    "input_sizes = [inputs['input_ids'].shape, inputs['attention_mask'].shape]\n",
    "input_types = [inputs['input_ids'].dtype, inputs['attention_mask'].dtype]\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(summary(\n",
    "        model, \n",
    "        input_size=input_sizes, \n",
    "        dtypes=input_types, \n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable']\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el modelo tiene una capa `BertModel` que corresponde al modelo pre-entrenado y finaliza con una capa lineal que sería nuestro clasificador, esta es una capa proporcionada para nosotros al momento de inicializar el modelo. Además, observamos que solamente la capa lineal que hemos especificado tiene parámetros entrenables. Entonces, a pesar de que el modelo en si tiene más de 100 millones de parámetros, solamente menos de 10 mil son entrenables.\n",
    "\n",
    "Observemos todos los modulos registrados en el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'bert',\n",
       " 'bert.embeddings',\n",
       " 'bert.embeddings.word_embeddings',\n",
       " 'bert.embeddings.position_embeddings',\n",
       " 'bert.embeddings.token_type_embeddings',\n",
       " 'bert.embeddings.LayerNorm',\n",
       " 'bert.embeddings.dropout',\n",
       " 'bert.encoder',\n",
       " 'bert.encoder.layer',\n",
       " 'bert.encoder.layer.0',\n",
       " 'bert.encoder.layer.0.attention',\n",
       " 'bert.encoder.layer.0.attention.self',\n",
       " 'bert.encoder.layer.0.attention.self.query',\n",
       " 'bert.encoder.layer.0.attention.self.key',\n",
       " 'bert.encoder.layer.0.attention.self.value',\n",
       " 'bert.encoder.layer.0.attention.self.dropout',\n",
       " 'bert.encoder.layer.0.attention.output',\n",
       " 'bert.encoder.layer.0.attention.output.dense',\n",
       " 'bert.encoder.layer.0.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.0.attention.output.dropout',\n",
       " 'bert.encoder.layer.0.intermediate',\n",
       " 'bert.encoder.layer.0.intermediate.dense',\n",
       " 'bert.encoder.layer.0.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.0.output',\n",
       " 'bert.encoder.layer.0.output.dense',\n",
       " 'bert.encoder.layer.0.output.LayerNorm',\n",
       " 'bert.encoder.layer.0.output.dropout',\n",
       " 'bert.encoder.layer.1',\n",
       " 'bert.encoder.layer.1.attention',\n",
       " 'bert.encoder.layer.1.attention.self',\n",
       " 'bert.encoder.layer.1.attention.self.query',\n",
       " 'bert.encoder.layer.1.attention.self.key',\n",
       " 'bert.encoder.layer.1.attention.self.value',\n",
       " 'bert.encoder.layer.1.attention.self.dropout',\n",
       " 'bert.encoder.layer.1.attention.output',\n",
       " 'bert.encoder.layer.1.attention.output.dense',\n",
       " 'bert.encoder.layer.1.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.1.attention.output.dropout',\n",
       " 'bert.encoder.layer.1.intermediate',\n",
       " 'bert.encoder.layer.1.intermediate.dense',\n",
       " 'bert.encoder.layer.1.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.1.output',\n",
       " 'bert.encoder.layer.1.output.dense',\n",
       " 'bert.encoder.layer.1.output.LayerNorm',\n",
       " 'bert.encoder.layer.1.output.dropout',\n",
       " 'bert.encoder.layer.2',\n",
       " 'bert.encoder.layer.2.attention',\n",
       " 'bert.encoder.layer.2.attention.self',\n",
       " 'bert.encoder.layer.2.attention.self.query',\n",
       " 'bert.encoder.layer.2.attention.self.key',\n",
       " 'bert.encoder.layer.2.attention.self.value',\n",
       " 'bert.encoder.layer.2.attention.self.dropout',\n",
       " 'bert.encoder.layer.2.attention.output',\n",
       " 'bert.encoder.layer.2.attention.output.dense',\n",
       " 'bert.encoder.layer.2.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.2.attention.output.dropout',\n",
       " 'bert.encoder.layer.2.intermediate',\n",
       " 'bert.encoder.layer.2.intermediate.dense',\n",
       " 'bert.encoder.layer.2.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.2.output',\n",
       " 'bert.encoder.layer.2.output.dense',\n",
       " 'bert.encoder.layer.2.output.LayerNorm',\n",
       " 'bert.encoder.layer.2.output.dropout',\n",
       " 'bert.encoder.layer.3',\n",
       " 'bert.encoder.layer.3.attention',\n",
       " 'bert.encoder.layer.3.attention.self',\n",
       " 'bert.encoder.layer.3.attention.self.query',\n",
       " 'bert.encoder.layer.3.attention.self.key',\n",
       " 'bert.encoder.layer.3.attention.self.value',\n",
       " 'bert.encoder.layer.3.attention.self.dropout',\n",
       " 'bert.encoder.layer.3.attention.output',\n",
       " 'bert.encoder.layer.3.attention.output.dense',\n",
       " 'bert.encoder.layer.3.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.3.attention.output.dropout',\n",
       " 'bert.encoder.layer.3.intermediate',\n",
       " 'bert.encoder.layer.3.intermediate.dense',\n",
       " 'bert.encoder.layer.3.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.3.output',\n",
       " 'bert.encoder.layer.3.output.dense',\n",
       " 'bert.encoder.layer.3.output.LayerNorm',\n",
       " 'bert.encoder.layer.3.output.dropout',\n",
       " 'bert.encoder.layer.4',\n",
       " 'bert.encoder.layer.4.attention',\n",
       " 'bert.encoder.layer.4.attention.self',\n",
       " 'bert.encoder.layer.4.attention.self.query',\n",
       " 'bert.encoder.layer.4.attention.self.key',\n",
       " 'bert.encoder.layer.4.attention.self.value',\n",
       " 'bert.encoder.layer.4.attention.self.dropout',\n",
       " 'bert.encoder.layer.4.attention.output',\n",
       " 'bert.encoder.layer.4.attention.output.dense',\n",
       " 'bert.encoder.layer.4.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.4.attention.output.dropout',\n",
       " 'bert.encoder.layer.4.intermediate',\n",
       " 'bert.encoder.layer.4.intermediate.dense',\n",
       " 'bert.encoder.layer.4.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.4.output',\n",
       " 'bert.encoder.layer.4.output.dense',\n",
       " 'bert.encoder.layer.4.output.LayerNorm',\n",
       " 'bert.encoder.layer.4.output.dropout',\n",
       " 'bert.encoder.layer.5',\n",
       " 'bert.encoder.layer.5.attention',\n",
       " 'bert.encoder.layer.5.attention.self',\n",
       " 'bert.encoder.layer.5.attention.self.query',\n",
       " 'bert.encoder.layer.5.attention.self.key',\n",
       " 'bert.encoder.layer.5.attention.self.value',\n",
       " 'bert.encoder.layer.5.attention.self.dropout',\n",
       " 'bert.encoder.layer.5.attention.output',\n",
       " 'bert.encoder.layer.5.attention.output.dense',\n",
       " 'bert.encoder.layer.5.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.5.attention.output.dropout',\n",
       " 'bert.encoder.layer.5.intermediate',\n",
       " 'bert.encoder.layer.5.intermediate.dense',\n",
       " 'bert.encoder.layer.5.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.5.output',\n",
       " 'bert.encoder.layer.5.output.dense',\n",
       " 'bert.encoder.layer.5.output.LayerNorm',\n",
       " 'bert.encoder.layer.5.output.dropout',\n",
       " 'bert.encoder.layer.6',\n",
       " 'bert.encoder.layer.6.attention',\n",
       " 'bert.encoder.layer.6.attention.self',\n",
       " 'bert.encoder.layer.6.attention.self.query',\n",
       " 'bert.encoder.layer.6.attention.self.key',\n",
       " 'bert.encoder.layer.6.attention.self.value',\n",
       " 'bert.encoder.layer.6.attention.self.dropout',\n",
       " 'bert.encoder.layer.6.attention.output',\n",
       " 'bert.encoder.layer.6.attention.output.dense',\n",
       " 'bert.encoder.layer.6.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.6.attention.output.dropout',\n",
       " 'bert.encoder.layer.6.intermediate',\n",
       " 'bert.encoder.layer.6.intermediate.dense',\n",
       " 'bert.encoder.layer.6.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.6.output',\n",
       " 'bert.encoder.layer.6.output.dense',\n",
       " 'bert.encoder.layer.6.output.LayerNorm',\n",
       " 'bert.encoder.layer.6.output.dropout',\n",
       " 'bert.encoder.layer.7',\n",
       " 'bert.encoder.layer.7.attention',\n",
       " 'bert.encoder.layer.7.attention.self',\n",
       " 'bert.encoder.layer.7.attention.self.query',\n",
       " 'bert.encoder.layer.7.attention.self.key',\n",
       " 'bert.encoder.layer.7.attention.self.value',\n",
       " 'bert.encoder.layer.7.attention.self.dropout',\n",
       " 'bert.encoder.layer.7.attention.output',\n",
       " 'bert.encoder.layer.7.attention.output.dense',\n",
       " 'bert.encoder.layer.7.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.7.attention.output.dropout',\n",
       " 'bert.encoder.layer.7.intermediate',\n",
       " 'bert.encoder.layer.7.intermediate.dense',\n",
       " 'bert.encoder.layer.7.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.7.output',\n",
       " 'bert.encoder.layer.7.output.dense',\n",
       " 'bert.encoder.layer.7.output.LayerNorm',\n",
       " 'bert.encoder.layer.7.output.dropout',\n",
       " 'bert.encoder.layer.8',\n",
       " 'bert.encoder.layer.8.attention',\n",
       " 'bert.encoder.layer.8.attention.self',\n",
       " 'bert.encoder.layer.8.attention.self.query',\n",
       " 'bert.encoder.layer.8.attention.self.key',\n",
       " 'bert.encoder.layer.8.attention.self.value',\n",
       " 'bert.encoder.layer.8.attention.self.dropout',\n",
       " 'bert.encoder.layer.8.attention.output',\n",
       " 'bert.encoder.layer.8.attention.output.dense',\n",
       " 'bert.encoder.layer.8.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.8.attention.output.dropout',\n",
       " 'bert.encoder.layer.8.intermediate',\n",
       " 'bert.encoder.layer.8.intermediate.dense',\n",
       " 'bert.encoder.layer.8.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.8.output',\n",
       " 'bert.encoder.layer.8.output.dense',\n",
       " 'bert.encoder.layer.8.output.LayerNorm',\n",
       " 'bert.encoder.layer.8.output.dropout',\n",
       " 'bert.encoder.layer.9',\n",
       " 'bert.encoder.layer.9.attention',\n",
       " 'bert.encoder.layer.9.attention.self',\n",
       " 'bert.encoder.layer.9.attention.self.query',\n",
       " 'bert.encoder.layer.9.attention.self.key',\n",
       " 'bert.encoder.layer.9.attention.self.value',\n",
       " 'bert.encoder.layer.9.attention.self.dropout',\n",
       " 'bert.encoder.layer.9.attention.output',\n",
       " 'bert.encoder.layer.9.attention.output.dense',\n",
       " 'bert.encoder.layer.9.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.9.attention.output.dropout',\n",
       " 'bert.encoder.layer.9.intermediate',\n",
       " 'bert.encoder.layer.9.intermediate.dense',\n",
       " 'bert.encoder.layer.9.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.9.output',\n",
       " 'bert.encoder.layer.9.output.dense',\n",
       " 'bert.encoder.layer.9.output.LayerNorm',\n",
       " 'bert.encoder.layer.9.output.dropout',\n",
       " 'bert.encoder.layer.10',\n",
       " 'bert.encoder.layer.10.attention',\n",
       " 'bert.encoder.layer.10.attention.self',\n",
       " 'bert.encoder.layer.10.attention.self.query',\n",
       " 'bert.encoder.layer.10.attention.self.key',\n",
       " 'bert.encoder.layer.10.attention.self.value',\n",
       " 'bert.encoder.layer.10.attention.self.dropout',\n",
       " 'bert.encoder.layer.10.attention.output',\n",
       " 'bert.encoder.layer.10.attention.output.dense',\n",
       " 'bert.encoder.layer.10.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.10.attention.output.dropout',\n",
       " 'bert.encoder.layer.10.intermediate',\n",
       " 'bert.encoder.layer.10.intermediate.dense',\n",
       " 'bert.encoder.layer.10.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.10.output',\n",
       " 'bert.encoder.layer.10.output.dense',\n",
       " 'bert.encoder.layer.10.output.LayerNorm',\n",
       " 'bert.encoder.layer.10.output.dropout',\n",
       " 'bert.encoder.layer.11',\n",
       " 'bert.encoder.layer.11.attention',\n",
       " 'bert.encoder.layer.11.attention.self',\n",
       " 'bert.encoder.layer.11.attention.self.query',\n",
       " 'bert.encoder.layer.11.attention.self.key',\n",
       " 'bert.encoder.layer.11.attention.self.value',\n",
       " 'bert.encoder.layer.11.attention.self.dropout',\n",
       " 'bert.encoder.layer.11.attention.output',\n",
       " 'bert.encoder.layer.11.attention.output.dense',\n",
       " 'bert.encoder.layer.11.attention.output.LayerNorm',\n",
       " 'bert.encoder.layer.11.attention.output.dropout',\n",
       " 'bert.encoder.layer.11.intermediate',\n",
       " 'bert.encoder.layer.11.intermediate.dense',\n",
       " 'bert.encoder.layer.11.intermediate.intermediate_act_fn',\n",
       " 'bert.encoder.layer.11.output',\n",
       " 'bert.encoder.layer.11.output.dense',\n",
       " 'bert.encoder.layer.11.output.LayerNorm',\n",
       " 'bert.encoder.layer.11.output.dropout',\n",
       " 'dropout',\n",
       " 'classifier']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules = [m for m, _ in model.named_modules()]\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que la capa final es efectivamente el clasificador. Ahora hagamos una prueba pasando un dummy input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': torch.Size([1, 10, 7])}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "print({k: v.shape for k, v in outputs.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 1, 1, 2, 1, 3, 2, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits=outputs.logits\n",
    "pred_ids = torch.argmax(logits, dim=-1) \n",
    "pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=7, bias=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que tras invocar el modelo, en efecto, obtenemos una salida de 7 dimensiones x cada token, correspondientes al número de labels.\n",
    "\n",
    "Ahora preparemos los datos para el entrenamiento.\n",
    "\n",
    "Hugging Face Datasets convenientemente implementa una función para hacer el train-test split en nuestro dataset y automáticamente creará nuevas llaves en el mismo para diferenciarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = dataset.train_test_split(train_size=0.8)\n",
    "validation_dataset = training_dataset['test'].train_test_split(train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "new_dataset = DatasetDict({\n",
    "    'train': training_dataset['train'],\n",
    "    'val': validation_dataset['train'],\n",
    "    'test': validation_dataset['test'],\n",
    "})\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos nuestros tres conjuntos, sin embargo, esto es la información cruda, debemos preparar los datos para el modelo, lo gual incluye tokenizar y convertir las categorías a ids. Preparamos entonces unas funciones utilitarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def label_names_2_ids(batch):\\n    batch['label'] = label2id[batch['category']]\\n    return batch\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_function(max_len):\n",
    "    def _preprocess_function(examples):\n",
    "        return tokenizer(examples['text'], max_length=max_len, truncation=True, padding='max_length')\n",
    "    return _preprocess_function\n",
    "\n",
    "def tokenize(max_len: int = 8):\n",
    "    def _tokenize(batch):\n",
    "        return tokenizer(batch['text'], max_length=max_len, truncation=True, padding='max_length')\n",
    "    return _tokenize\n",
    "\n",
    "'''def label_names_2_ids(batch):\n",
    "    batch['label'] = label2id[batch['category']]\n",
    "    return batch'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y procedemos a invocarlas. Nótese que para la tokenización, estamos forzando a que las cadenas sean de 512 tokens, según el análisis que hemos hecho anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, max_len=512):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    label_ids = []\n",
    "\n",
    "    for tokens, ner_tags in zip(examples[\"tokens\"], examples[\"ner_tags\"]):\n",
    "        # Convert tokens to IDs\n",
    "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # Truncate both ids and labels\n",
    "        ids = ids[:max_len]\n",
    "        labels = ner_tags[:max_len]\n",
    "\n",
    "        # Pad input_ids\n",
    "        padding_length = max_len - len(ids)\n",
    "        ids = ids + [tokenizer.pad_token_id] * padding_length\n",
    "        mask = [1] * len(tokens[:max_len]) + [0] * padding_length\n",
    "\n",
    "        # Pad labels with -100 (so loss ignores them)\n",
    "        labels = labels + [-100] * padding_length\n",
    "\n",
    "        input_ids.append(ids)\n",
    "        attention_masks.append(mask)\n",
    "        label_ids.append(labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"labels\": label_ids\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16000/16000 [00:02<00:00, 7369.10 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 7584.99 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 7377.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = new_dataset.map(\n",
    "    lambda batch: preprocess_function(batch, max_len=512),\n",
    "    batched=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs', 'spans', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "Ahora procederemos al entrenamiento. Aquí harémos uso de las API de HuggingFace directamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from typing import Dict, Any\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']  # <-- replace with your labels\n",
    "id2label = {i: l for i, l in enumerate(label_list)}\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute standard classification metrics (accuracy, precision, recall, f1).\n",
    "    \"\"\"\n",
    "    predictions = np.argmax(pred.predictions, axis=-1)\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    # Flatten predictions and labels, ignoring -100 (padding tokens)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l != -100:\n",
    "                true_predictions.append(p)\n",
    "                true_labels.append(l)\n",
    "\n",
    "    acc = accuracy_score(true_labels, true_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, true_predictions, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Batch size depending on your environment\n",
    "batch_size = 8\n",
    "logging_steps = len(tokenized_dataset[\"train\"]) // batch_size\n",
    "\n",
    "# ✅ Training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./hf-ner',\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',   \n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='tensorboard'\n",
    ")\n",
    "\n",
    "# ✅ Trainer for NER\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics for token classification\n",
    "# -----------------------------\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute per-token classification metrics.\n",
    "    Ignores labels set to -100 (padding tokens)\n",
    "    \"\"\"\n",
    "    predictions = np.argmax(pred.predictions, axis=-1)\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    true_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l != -100:\n",
    "                true_preds.append(p)\n",
    "                true_labels.append(l)\n",
    "\n",
    "    acc = accuracy_score(true_labels, true_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        true_labels, true_preds, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# -----------------------------\n",
    "# Training arguments\n",
    "# -----------------------------\n",
    "batch_size = 4  \n",
    "logging_steps = len(tokenized_dataset['train']) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./hf-ner',\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=5e-4,  \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='tensorboard'\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Freeze BERT base\n",
    "# -----------------------------\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# -----------------------------\n",
    "# Trainer\n",
    "# -----------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto nos basta para ejecutar el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 4414/12000 [40:47<1:10:05,  1.80it/s]\n",
      " 50%|█████     | 4000/8000 [05:15<05:14, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9174, 'grad_norm': 5.982828140258789, 'learning_rate': 0.00025, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4000/8000 [05:25<05:14, 12.73it/s]\n",
      " 50%|█████     | 4000/8000 [05:52<05:14, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.773411750793457, 'eval_accuracy': 0.7358827179646292, 'eval_precision': 0.7049471897392444, 'eval_recall': 0.625534703329958, 'eval_f1': 0.6577347297658004, 'eval_runtime': 37.2435, 'eval_samples_per_second': 53.701, 'eval_steps_per_second': 13.425, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:10<00:00, 12.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.913, 'grad_norm': 4.355657577514648, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:21<00:00, 12.56it/s]\n",
      "100%|██████████| 8000/8000 [11:48<00:00, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7712481617927551, 'eval_accuracy': 0.7372789326714242, 'eval_precision': 0.7056923203862873, 'eval_recall': 0.628785570436496, 'eval_f1': 0.6603764036537869, 'eval_runtime': 37.3089, 'eval_samples_per_second': 53.607, 'eval_steps_per_second': 13.402, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:48<00:00, 11.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 708.9533, 'train_samples_per_second': 45.137, 'train_steps_per_second': 11.284, 'train_loss': 0.9152194213867187, 'epoch': 2.0}\n",
      "CPU times: user 11min 29s, sys: 21.3 s, total: 11min 50s\n",
      "Wall time: 11min 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.9152194213867187, metrics={'train_runtime': 708.9533, 'train_samples_per_second': 45.137, 'train_steps_per_second': 11.284, 'total_flos': 8361874194432000.0, 'train_loss': 0.9152194213867187, 'epoch': 2.0})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo importante a resaltar es que fueron necesarias solo 2 iteraciones para alcanzar un tasa de correctitud $\\approx 73%$, algo que con el modelo de transformers crudo nos costó muchas más iteraciones. Esto demuestra la importancia de partir de modelos pre-entrenados para este tipo de tareas.\n",
    "\n",
    "Una ventaja adicional de Hugging Face transformers, es que publica automáticamente el progreso del entrenamiento a tensorboard, en el directorio que hemos especificado. Observemos entonces el proceso de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir hf/runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora evaluemos el modelo en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:36<00:00, 13.61it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.779617190361023,\n",
       " 'eval_accuracy': 0.7317828226702652,\n",
       " 'eval_precision': 0.7044710031223422,\n",
       " 'eval_recall': 0.6271342428179869,\n",
       " 'eval_f1': 0.6573209722608893,\n",
       " 'eval_runtime': 36.8215,\n",
       " 'eval_samples_per_second': 54.316,\n",
       " 'eval_steps_per_second': 13.579,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos alcanzado una correctitud del $\\approx 80\\%$, lo cual, nuevamente, en comparación con el modelo de transformers crudo nos costó muchisimo más lograr.\n",
    "\n",
    "### Haciendo uso del modelo\n",
    "Ahora, hagamos predicciónes con el modelo y observemos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:36<00:00, 13.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[[ 3.698278  ,  2.1999195 , -2.791962  , ..., -4.5042505 ,\n",
       "          0.09645343, -5.8428087 ],\n",
       "        [ 0.93821156,  0.7717347 ,  0.29448378, ..., -2.2272525 ,\n",
       "         -1.4286265 , -2.9465032 ],\n",
       "        [ 0.34353563, -0.11507095,  0.977844  , ..., -1.5054938 ,\n",
       "         -2.284584  , -2.280034  ],\n",
       "        ...,\n",
       "        [ 2.7984204 ,  1.460154  , -0.8538184 , ..., -2.759731  ,\n",
       "         -0.30901828, -3.9364414 ],\n",
       "        [ 2.5177102 ,  1.5391496 , -0.9198532 , ..., -2.706764  ,\n",
       "         -0.34798068, -3.7475448 ],\n",
       "        [ 2.3703907 ,  0.9172478 , -0.58972645, ..., -2.330913  ,\n",
       "         -0.652017  , -3.5605698 ]],\n",
       "\n",
       "       [[ 2.1262493 , -2.197167  , -5.798137  , ..., -1.5983897 ,\n",
       "          1.9094486 , -2.2015743 ],\n",
       "        [ 0.08091775, -3.7032917 , -3.5509198 , ...,  0.4340486 ,\n",
       "          1.1929848 ,  0.06223092],\n",
       "        [ 1.1157013 , -7.333284  , -2.683442  , ...,  2.8952367 ,\n",
       "         -3.601121  ,  1.4687955 ],\n",
       "        ...,\n",
       "        [ 1.7722653 , -2.08081   , -4.025118  , ..., -0.4521977 ,\n",
       "          1.091702  , -0.67527807],\n",
       "        [ 1.6547313 , -2.155594  , -3.979571  , ..., -0.3701855 ,\n",
       "          1.1716053 , -0.6589042 ],\n",
       "        [ 1.2114385 , -3.0672963 , -3.923995  , ...,  0.15505551,\n",
       "          1.1329961 , -0.436328  ]],\n",
       "\n",
       "       [[ 2.412836  ,  2.025291  , -1.6626263 , ..., -4.0713882 ,\n",
       "         -0.26961237, -4.773653  ],\n",
       "        [ 0.49258888,  0.49130216,  1.0800941 , ..., -2.283684  ,\n",
       "         -1.7011814 , -2.352912  ],\n",
       "        [ 0.03435624, -0.17530593,  1.6260332 , ..., -1.8261858 ,\n",
       "         -2.2380888 , -1.8118104 ],\n",
       "        ...,\n",
       "        [ 2.0011406 ,  1.6114383 , -0.19755395, ..., -2.7971687 ,\n",
       "         -0.40993726, -3.4171236 ],\n",
       "        [ 1.6835102 ,  1.6400008 , -0.19270243, ..., -2.7235718 ,\n",
       "         -0.51334035, -3.207049  ],\n",
       "        [ 1.6819464 ,  0.9894874 ,  0.10715295, ..., -2.3569348 ,\n",
       "         -0.813148  , -3.0175772 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.5755904 ,  0.891035  , -0.9846747 , ..., -2.301541  ,\n",
       "          0.39197683, -1.2653997 ],\n",
       "        [-1.5578552 , -1.426172  ,  1.8513321 , ..., -0.15308139,\n",
       "         -1.8183501 ,  1.4697933 ],\n",
       "        [-2.8016272 , -1.6174304 ,  2.322832  , ...,  0.27431044,\n",
       "         -1.3695719 ,  1.9982752 ],\n",
       "        ...,\n",
       "        [ 0.9336846 ,  1.1322684 ,  0.38025862, ..., -1.6817902 ,\n",
       "         -0.28398937, -1.0627728 ],\n",
       "        [ 0.7312827 ,  1.0937965 ,  0.45472845, ..., -1.7000496 ,\n",
       "         -0.02145499, -1.0150427 ],\n",
       "        [ 0.70966005,  0.42928907,  0.3647268 , ..., -1.3429517 ,\n",
       "         -0.4904104 , -0.711019  ]],\n",
       "\n",
       "       [[ 2.9362648 ,  2.5326395 , -0.9391854 , ..., -5.04499   ,\n",
       "         -0.9086906 , -5.935389  ],\n",
       "        [ 1.488807  ,  0.4725274 ,  1.5682006 , ..., -3.1230216 ,\n",
       "         -1.3146036 , -3.3962235 ],\n",
       "        [ 0.7381216 , -0.91638786,  2.6268566 , ..., -2.3754046 ,\n",
       "         -1.4265695 , -3.1484046 ],\n",
       "        ...,\n",
       "        [ 3.36196   ,  1.1572917 ,  0.50547636, ..., -3.4740412 ,\n",
       "         -1.5340502 , -3.7969737 ],\n",
       "        [ 3.2473385 ,  1.2687808 ,  0.48082504, ..., -3.4519315 ,\n",
       "         -1.495764  , -3.7342305 ],\n",
       "        [ 2.4867125 ,  0.65543395,  0.9070295 , ..., -3.1803336 ,\n",
       "         -1.3729975 , -3.7008405 ]],\n",
       "\n",
       "       [[ 0.35231325, -0.8910607 , -3.2604277 , ..., -1.1920921 ,\n",
       "          0.87601197, -2.5197997 ],\n",
       "        [-2.165141  , -3.7560117 ,  0.13927592, ...,  1.68916   ,\n",
       "         -2.299083  ,  1.6292635 ],\n",
       "        [-2.4360728 , -4.2208753 ,  0.45326915, ...,  3.1323647 ,\n",
       "         -4.1848845 ,  2.3588178 ],\n",
       "        ...,\n",
       "        [ 0.42474064, -0.5240951 , -1.8622674 , ..., -0.5097313 ,\n",
       "          0.34633794, -1.3752836 ],\n",
       "        [ 0.05344146, -0.45258272, -1.6961416 , ..., -0.44280082,\n",
       "          0.43809664, -1.2687676 ],\n",
       "        [-0.29611674, -1.0041466 , -1.4402686 , ..., -0.10657717,\n",
       "          0.3244021 , -0.7989573 ]]], dtype=float32), label_ids=array([[   0,    1,    2, ..., -100, -100, -100],\n",
       "       [   3,    4,    4, ..., -100, -100, -100],\n",
       "       [   3,    4,    4, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [   1,    2,    2, ..., -100, -100, -100],\n",
       "       [   0,    1,    2, ..., -100, -100, -100],\n",
       "       [   3,    4,    4, ..., -100, -100, -100]]), metrics={'test_loss': 0.779617190361023, 'test_accuracy': 0.7317828226702652, 'test_precision': 0.7044710031223422, 'test_recall': 0.6271342428179869, 'test_f1': 0.6573209722608893, 'test_runtime': 36.9719, 'test_samples_per_second': 54.095, 'test_steps_per_second': 13.524})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dataset['test'])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# predictions.predictions: shape (num_batches, seq_len, num_labels)\n",
    "predicted_label_ids = np.argmax(predictions.predictions, axis=-1)  # shape (num_batches, seq_len)\n",
    "\n",
    "# Flatten para iterar sobre cada ejemplo\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for pred_seq, label_seq in zip(predicted_label_ids, predictions.label_ids):\n",
    "    # filtra los tokens con label = -100\n",
    "    filtered_pred = [id2label[p] for p, l in zip(pred_seq, label_seq) if l != -100]\n",
    "    filtered_label = [id2label[l] for l in label_seq if l != -100]\n",
    "    \n",
    "    all_preds.append(filtered_pred)\n",
    "    all_labels.append(filtered_label)\n",
    "\n",
    "\n",
    "\n",
    "test_set = tokenized_dataset['test'].remove_columns(['labels'])  # opcional\n",
    "test_set = test_set.add_column(\"predictions\", all_preds)\n",
    "test_set = test_set.add_column(\"true_labels\", all_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 0 ===\n",
      "[UNK]            True: O           Pred: O         \n",
      "[UNK]            True: B-PER       Pred: O         \n",
      "[UNK]            True: I-PER       Pred: I-PER     \n",
      "[UNK]            True: I-PER       Pred: I-PER     \n",
      "\n",
      "=== Example 1 ===\n",
      "[UNK]            True: B-ORG       Pred: O         \n",
      "Avenida          True: I-ORG       Pred: B-ORG     \n",
      "(                True: I-ORG       Pred: I-ORG     \n",
      "línea            True: I-ORG       Pred: I-ORG     \n",
      "[UNK]            True: I-ORG       Pred: I-ORG     \n",
      "End              True: I-ORG       Pred: I-ORG     \n",
      ")                True: I-ORG       Pred: I-ORG     \n",
      "\n",
      "=== Example 2 ===\n",
      "[UNK]            True: B-ORG       Pred: O         \n",
      "[UNK]            True: I-ORG       Pred: I-PER     \n",
      "[UNK]            True: I-ORG       Pred: I-PER     \n",
      "\n",
      "=== Example 3 ===\n",
      "[UNK]            True: B-LOC       Pred: B-LOC     \n",
      "Point            True: I-LOC       Pred: B-LOC     \n",
      "(                True: I-LOC       Pred: I-LOC     \n",
      "[UNK]            True: I-LOC       Pred: I-LOC     \n",
      ")                True: I-LOC       Pred: I-LOC     \n",
      "\n",
      "=== Example 4 ===\n",
      "[UNK]            True: O           Pred: O         \n",
      "[UNK]            True: B-PER       Pred: O         \n",
      "[UNK]            True: I-PER       Pred: I-PER     \n",
      "Morgan           True: I-PER       Pred: I-PER     \n",
      ",                True: I-PER       Pred: O         \n",
      "[UNK]            True: I-PER       Pred: I-PER     \n",
      ".                True: I-PER       Pred: O         \n",
      "\n",
      "=== Example 5 ===\n",
      "Inmigración      True: B-ORG       Pred: O         \n",
      "italiana         True: I-ORG       Pred: O         \n",
      "en               True: I-ORG       Pred: O         \n",
      "Estados          True: I-ORG       Pred: B-LOC     \n",
      "Unidos           True: I-ORG       Pred: I-LOC     \n",
      "\n",
      "=== Example 6 ===\n",
      "[UNK]            True: O           Pred: O         \n",
      "Primer           True: B-ORG       Pred: B-ORG     \n",
      "Imperio          True: I-ORG       Pred: I-ORG     \n",
      "[UNK]            True: I-ORG       Pred: I-ORG     \n",
      "\n",
      "=== Example 7 ===\n",
      "[UNK]            True: O           Pred: O         \n",
      "[UNK]            True: B-LOC       Pred: B-LOC     \n",
      "de               True: I-LOC       Pred: I-PER     \n",
      "[UNK]            True: I-LOC       Pred: I-PER     \n",
      "\n",
      "=== Example 8 ===\n",
      "[UNK]            True: O           Pred: B-PER     \n",
      "Isabel           True: B-PER       Pred: B-PER     \n",
      "de               True: I-PER       Pred: I-PER     \n",
      "[UNK]            True: I-PER       Pred: I-PER     \n",
      "\n",
      "=== Example 9 ===\n",
      "Se               True: O           Pred: O         \n",
      "pueden           True: O           Pred: O         \n",
      "encontrar        True: O           Pred: O         \n",
      "en               True: O           Pred: O         \n",
      "Brasil           True: B-LOC       Pred: B-LOC     \n",
      ".                True: O           Pred: O         \n"
     ]
    }
   ],
   "source": [
    "n_examples = 10  \n",
    "\n",
    "for i in range(n_examples):\n",
    "    print(f\"\\n=== Example {i} ===\")\n",
    "    tokens = test_set[i]['input_ids']\n",
    "    true_labels = test_set[i]['true_labels']\n",
    "    pred_labels = test_set[i]['predictions']\n",
    "\n",
    "    for token_id, t_label, p_label in zip(tokens, true_labels, pred_labels):\n",
    "        token_str = tokenizer.decode([token_id])\n",
    "        print(f\"{token_str:15}  True: {t_label:10}  Pred: {p_label:10}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores parece que son en su  mayoria debido a un token desconocido, perjudicando asi en los resultados. Sin embargo, con todo y estos [UNK], el modelo se comporta bastante bien con 2 epocas.\n",
    "\n",
    "## Usando una capa más especializada como clasificador\n",
    "\n",
    "Quizás podemos hacerlo mejor, hemos observado que por defecto, cuando cargamos la clase, Hugging Face nos da un clasificador muy simple, solo una capa lineal. Pero podemos utilizar un clasificador más complejo que definamos nosotros. Esta técnica seguiría utilizando el resto del modelo como featurizer, pero ahora añadimos complejidad a la capa de clasificación en búsqueda de una mejor calidad en los resutlados.\n",
    "\n",
    "Entonces, volvemos a cargar el modelo tal como hemos hecho antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Input Shapes & Types:\n",
      "{'input_ids': (torch.Size([1, 10]), torch.int64), 'token_type_ids': (torch.Size([1, 10]), torch.int64), 'attention_mask': (torch.Size([1, 10]), torch.int64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
      "================================================================================================================================================================\n",
      "BertForTokenClassification                                   [1, 10]                   [1, 10, 7]                --                        Partial\n",
      "├─BertModel: 1-1                                             [1, 10]                   [1, 10, 768]              --                        False\n",
      "│    └─BertEmbeddings: 2-1                                   --                        [1, 10, 768]              --                        False\n",
      "│    │    └─Embedding: 3-1                                   [1, 10]                   [1, 10, 768]              (23,809,536)              False\n",
      "│    │    └─Embedding: 3-2                                   [1, 10]                   [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Embedding: 3-3                                   [1, 10]                   [1, 10, 768]              (393,216)                 False\n",
      "│    │    └─LayerNorm: 3-4                                   [1, 10, 768]              [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Dropout: 3-5                                     [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "│    └─BertEncoder: 2-2                                      [1, 10, 768]              [1, 10, 768]              --                        False\n",
      "│    │    └─ModuleList: 3-6                                  --                        --                        (85,054,464)              False\n",
      "├─Dropout: 1-2                                               [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "├─Linear: 1-3                                                [1, 10, 768]              [1, 10, 7]                5,383                     True\n",
      "================================================================================================================================================================\n",
      "Total params: 109,265,671\n",
      "Trainable params: 5,383\n",
      "Non-trainable params: 109,260,288\n",
      "Total mult-adds (Units.MEGABYTES): 109.27\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 8.36\n",
      "Params size (MB): 437.06\n",
      "Estimated Total Size (MB): 445.42\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "# Ejemplo de texto\n",
    "inputs = tokenizer(\"Hola Mundo!!!\", \n",
    "                   max_length=10, \n",
    "                   truncation=True, \n",
    "                   padding='max_length', \n",
    "                   return_tensors='pt')\n",
    "\n",
    "print(\"Input Shapes & Types:\")\n",
    "print({k: (v.shape, v.dtype) for k, v in inputs.items()})\n",
    "\n",
    "# Definición de etiquetas (ejemplo NER: O, PER, LOC, ORG)\n",
    "label2id = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-ORG\": 3, \"I-ORG\": 4, \"B-LOC\": 5, \"I-LOC\": 6}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Cargamos modelo para token classification (NER)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "# Congelamos pesos del modelo base\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# torchinfo necesita los inputs esperados: input_ids y attention_mask\n",
    "input_sizes = [inputs['input_ids'].shape, inputs['attention_mask'].shape]\n",
    "input_types = [inputs['input_ids'].dtype, inputs['attention_mask'].dtype]\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(summary(\n",
    "        model, \n",
    "        input_size=input_sizes, \n",
    "        dtypes=input_types, \n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=7, bias=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos un clasificador propio\n",
    "\n",
    "Podemos definir cualquier tipo de clasificador que se nos ocurra, siempre que se ajuste a las entradas y salidas del clasificador existente. Vamos a utilizar por ejemplo la misma capa lineal que definimos en el notebook anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                       Input Shape               Output Shape              Param #                   Trainable\n",
      "================================================================================================================================================================\n",
      "BertForTokenClassification                                   [1, 10]                   [1, 10, 7]                --                        Partial\n",
      "├─BertModel: 1-1                                             [1, 10]                   [1, 10, 768]              --                        False\n",
      "│    └─BertEmbeddings: 2-1                                   --                        [1, 10, 768]              --                        False\n",
      "│    │    └─Embedding: 3-1                                   [1, 10]                   [1, 10, 768]              (23,809,536)              False\n",
      "│    │    └─Embedding: 3-2                                   [1, 10]                   [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Embedding: 3-3                                   [1, 10]                   [1, 10, 768]              (393,216)                 False\n",
      "│    │    └─LayerNorm: 3-4                                   [1, 10, 768]              [1, 10, 768]              (1,536)                   False\n",
      "│    │    └─Dropout: 3-5                                     [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "│    └─BertEncoder: 2-2                                      [1, 10, 768]              [1, 10, 768]              --                        False\n",
      "│    │    └─ModuleList: 3-6                                  --                        --                        (85,054,464)              False\n",
      "├─Dropout: 1-2                                               [1, 10, 768]              [1, 10, 768]              --                        --\n",
      "├─Sequential: 1-3                                            [1, 10, 768]              [1, 10, 7]                --                        True\n",
      "│    └─Linear: 2-3                                           [1, 10, 768]              [1, 10, 512]              393,728                   True\n",
      "│    └─ReLU: 2-4                                             [1, 10, 512]              [1, 10, 512]              --                        --\n",
      "│    └─Dropout: 2-5                                          [1, 10, 512]              [1, 10, 512]              --                        --\n",
      "│    └─Linear: 2-6                                           [1, 10, 512]              [1, 10, 256]              131,328                   True\n",
      "│    └─ReLU: 2-7                                             [1, 10, 256]              [1, 10, 256]              --                        --\n",
      "│    └─Dropout: 2-8                                          [1, 10, 256]              [1, 10, 256]              --                        --\n",
      "│    └─Linear: 2-9                                           [1, 10, 256]              [1, 10, 7]                1,799                     True\n",
      "│    └─LogSoftmax: 2-10                                      [1, 10, 7]                [1, 10, 7]                --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 109,787,143\n",
      "Trainable params: 526,855\n",
      "Non-trainable params: 109,260,288\n",
      "Total mult-adds (Units.MEGABYTES): 109.79\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 8.42\n",
      "Params size (MB): 439.15\n",
      "Estimated Total Size (MB): 447.57\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(768, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 7),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# simplemente reemplazamos el clasificador existente por el nuestro:\n",
    "model.classifier = classifier\n",
    "with torch.no_grad():\n",
    "    print(summary(model, input_size=input_sizes, dtypes=input_types, col_names=['input_size', 'output_size', 'num_params', 'trainable']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.2, inplace=False)\n",
       "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Dropout(p=0.2, inplace=False)\n",
       "  (6): Linear(in_features=256, out_features=7, bias=True)\n",
       "  (7): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que nuestro modelo ya tiene más parámetros para entrenar, producto de nuestro nuevo clasificador.\n",
    "\n",
    "Procedemos a definir nuevamente el entrenador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y a entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4000/8000 [05:18<05:18, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8916, 'grad_norm': 8.400601387023926, 'learning_rate': 0.00025, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4000/8000 [05:28<05:18, 12.57it/s]\n",
      " 50%|█████     | 4000/8000 [05:55<05:18, 12.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6460847854614258, 'eval_accuracy': 0.7733478125969594, 'eval_precision': 0.7318793196021698, 'eval_recall': 0.6866983783498932, 'eval_f1': 0.7047237135245478, 'eval_runtime': 37.4409, 'eval_samples_per_second': 53.417, 'eval_steps_per_second': 13.354, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:16<00:00, 12.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7268, 'grad_norm': 2.5237667560577393, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:28<00:00, 12.50it/s]\n",
      "100%|██████████| 8000/8000 [11:54<00:00, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6080610156059265, 'eval_accuracy': 0.7894042817251008, 'eval_precision': 0.7490576400906157, 'eval_recall': 0.7025945848846192, 'eval_f1': 0.7224106121120986, 'eval_runtime': 37.4909, 'eval_samples_per_second': 53.346, 'eval_steps_per_second': 13.337, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [11:55<00:00, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 715.1473, 'train_samples_per_second': 44.746, 'train_steps_per_second': 11.187, 'train_loss': 0.8092391357421875, 'epoch': 2.0}\n",
      "CPU times: user 11min 42s, sys: 14.6 s, total: 11min 57s\n",
      "Wall time: 11min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8000, training_loss=0.8092391357421875, metrics={'train_runtime': 715.1473, 'train_samples_per_second': 44.746, 'train_steps_per_second': 11.187, 'total_flos': 8413136977920000.0, 'train_loss': 0.8092391357421875, 'epoch': 2.0})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y evaluamos el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:36<00:00, 13.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6205454468727112,\n",
       " 'eval_accuracy': 0.7798063184632481,\n",
       " 'eval_precision': 0.7446983891190077,\n",
       " 'eval_recall': 0.6926790751344455,\n",
       " 'eval_f1': 0.7129742186133446,\n",
       " 'eval_runtime': 37.0318,\n",
       " 'eval_samples_per_second': 54.008,\n",
       " 'eval_steps_per_second': 13.502,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido una ligera mejora en nuestro modelo, lo cual sugiere que nuestro clasificador más complejo contribuye a una mayor calidad de los resultados.\n",
    "\n",
    "## Fine Tuning con BERT\n",
    "\n",
    "Para terminar, ahora harémos fine tuning, es decir, vamos a dejar libres todas las capas del modelo base para que todas calculen gradiente y entrenen sobre nuestra tarea específica.\n",
    "\n",
    "En este caso entonces no necesitamos modificar nada del modelo original, podemos instanciarlo y proceder directamente al entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Input Shapes & Types:\n",
      "{'input_ids': (torch.Size([1, 10]), torch.int64), 'token_type_ids': (torch.Size([1, 10]), torch.int64), 'attention_mask': (torch.Size([1, 10]), torch.int64)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "# Ejemplo de texto\n",
    "inputs = tokenizer(\"Hola Mundo!!!\", \n",
    "                   max_length=10, \n",
    "                   truncation=True, \n",
    "                   padding='max_length', \n",
    "                   return_tensors='pt')\n",
    "\n",
    "print(\"Input Shapes & Types:\")\n",
    "print({k: (v.shape, v.dtype) for k, v in inputs.items()})\n",
    "\n",
    "# Definición de etiquetas (ejemplo NER: O, PER, LOC, ORG)\n",
    "label2id = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-ORG\": 3, \"I-ORG\": 4, \"B-LOC\": 5, \"I-LOC\": 6}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Cargamos modelo para token classification (NER)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_ckpt,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./hf-ner',\n",
    "    num_train_epochs=1, #este lo puse a 1 epoch porque me esta cogiendo la tarde para entregar \n",
    "    learning_rate=2e-5,  \n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=logging_steps,\n",
    "    report_to='tensorboard'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['val'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [16:25<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7008, 'grad_norm': 4.4914422035217285, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4000/4000 [17:01<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7018404006958008, 'eval_accuracy': 0.42243251628917156, 'eval_precision': 0.06034750232702451, 'eval_recall': 0.14285714285714285, 'eval_f1': 0.08485112880357727, 'eval_runtime': 36.406, 'eval_samples_per_second': 54.936, 'eval_steps_per_second': 13.734, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [17:03<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1023.6193, 'train_samples_per_second': 15.631, 'train_steps_per_second': 3.908, 'train_loss': 1.7007921142578124, 'epoch': 1.0}\n",
      "CPU times: user 17min, sys: 4.98 s, total: 17min 5s\n",
      "Wall time: 17min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=1.7007921142578124, metrics={'train_runtime': 1023.6193, 'train_samples_per_second': 15.631, 'train_steps_per_second': 3.908, 'total_flos': 4180937097216000.0, 'train_loss': 1.7007921142578124, 'epoch': 1.0})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:35<00:00, 13.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.7228543758392334,\n",
       " 'eval_accuracy': 0.40657247182092393,\n",
       " 'eval_precision': 0.05808178168870342,\n",
       " 'eval_recall': 0.14285714285714285,\n",
       " 'eval_f1': 0.08258626249596904,\n",
       " 'eval_runtime': 35.865,\n",
       " 'eval_samples_per_second': 55.765,\n",
       " 'eval_steps_per_second': 13.941,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "trainer.evaluate(tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi caso las metricas estan bastante bajas luego de hacer fine-tunning. Es cierto que hubiera siedo bien probar con mas epocas y de pronto un learning rate mas grande.  \n",
    "\n",
    "Feature extraction con BERT: Aunque solo entrenamos la capa superior sobre las representaciones preentrenadas de BERT, logramos un punto de partida sólido para NER. Con más epochs probablemente mejoraríamos el rendimiento, pero incluso así la estrategia permite entrenar rápido y evita sobreajuste.\n",
    "\n",
    "Fine-tuning: Entrenar todas las capas de BERT permitiría que el modelo se adapte mejor a nuestro dataset específico. Con 1 época las métricas fueron desastrosas, cosa que no se por que otro factor pueda ser usando exactamente las mismas configuraciones que antes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
